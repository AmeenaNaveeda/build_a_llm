{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpt import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_block): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx is a (batch_size, n_tokens) array of indices in the current context\n",
    "def generate_text_sample(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        \"\"\"\n",
    "        crops current context if it exceeds the supported context size\n",
    "        eg: if LLM supports only 5 tokens and the context size is 10\n",
    "        only 5 tokens are used as context\n",
    "        \"\"\"\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        \"\"\"\n",
    "        Focuses only on the last time step so that (batch_size, n_tokens, vocab_size)\n",
    "        becomes (batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "        logits = logits[:,-1,:]\n",
    "        # probas has shape (batch_size, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        # idx_next has shape (batch_size, 1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        \"\"\"\n",
    "        Append sampled index tot he running sequence\n",
    "        where idx has shape (batch, n_tokens+1)\n",
    "        \"\"\"\n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexAngel214nesiumfigured\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_sample(\n",
    "    model = model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Output text:\\n {token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text evaluation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833,3626,6100],       #every effor moves\n",
    "                       [40,1107,588]])          #I really like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626,6100,345],        #effort moves you\n",
    "                        [1107,588,11311]])      #really like chocolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Ids: tensor([[[16657],\n",
      "         [16031],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"Token Ids: {token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Output batch 1:  Armed savesNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Output batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.9576e-05, 1.5754e-05, 1.1587e-05,  ..., 2.1908e-05,\n",
       "          7.0255e-06, 1.8478e-05],\n",
       "         [9.4945e-06, 1.0247e-05, 7.7444e-06,  ..., 2.8397e-05,\n",
       "          6.1837e-06, 1.2869e-05],\n",
       "         [2.8746e-05, 8.5582e-06, 1.5153e-05,  ..., 3.7397e-05,\n",
       "          1.3669e-05, 1.2614e-05]],\n",
       "\n",
       "        [[1.2261e-05, 2.0023e-05, 1.3299e-05,  ..., 1.0177e-05,\n",
       "          3.5075e-05, 1.3706e-05],\n",
       "         [7.4842e-06, 1.7175e-05, 1.0332e-05,  ..., 2.1160e-05,\n",
       "          1.1552e-05, 1.4645e-05],\n",
       "         [2.8896e-05, 3.3004e-05, 4.2034e-05,  ..., 6.6369e-06,\n",
       "          5.7847e-05, 1.3099e-05]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.1165e-05, 3.1117e-05, 1.1661e-05])\n"
     ]
    }
   ],
   "source": [
    "text_ids = 0\n",
    "target_probas_1 = probas[text_ids, [0,1,2], targets[text_ids]]\n",
    "print(\"Text 1:\", target_probas_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 2: tensor([1.0360e-05, 5.3230e-05, 4.7808e-06])\n"
     ]
    }
   ],
   "source": [
    "text_ids = 1\n",
    "target_probas_2 = probas[text_ids, [0,1,2], targets[text_ids]]\n",
    "print(\"Text 2:\",target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5505, -10.3778, -11.3593, -11.4776,  -9.8409, -12.2509])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1,target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8095)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8095)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this can be done via a single function in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape:torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logits shape:{logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine batch size and number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flatteneed targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(f\"Flattened logits: {logits_flat.shape}\")\n",
    "print(f\"Flatteneed targets: {targets_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8095)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49487.9023)\n"
     ]
    }
   ],
   "source": [
    "preplexity = torch.exp(loss)\n",
    "print(preplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the verdict dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Total characters: {total_characters}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "test_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "test_loader = create_dataloader_v1(\n",
    "    test_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify created data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loaders:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Validation Loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train loaders:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(f\"Validation Loader\")\n",
    "for x, y in test_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy loss for batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i,(input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss/num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.986397849188911\n",
      "val_loss: 10.980345726013184\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cude\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device\n",
    "        )\n",
    "    val_loss = calc_loss_loader(\n",
    "        test_loader, model, device\n",
    "    )\n",
    "print(f\"Training loss: {train_loss}\")\n",
    "print(f\"val_loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                      )\n",
    "                \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample( model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_sample(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n',' '))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (step 000000): Train loss 9.753, Val loss 9.884\n",
      "Ep 1 (step 000005): Train loss 8.118, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (step 000010): Train loss 6.675, Val loss 7.051\n",
      "Ep 2 (step 000015): Train loss 5.997, Val loss 6.629\n",
      "Every effort moves you, and,, and,,,,,,, and,,,,,,,,,,,,,,,, and,,,, and,,,,,,,, and,,,,,,\n",
      "Ep 3 (step 000020): Train loss 5.746, Val loss 6.500\n",
      "Ep 3 (step 000025): Train loss 5.546, Val loss 6.433\n",
      "Every effort moves you, and, and I had to the to the, and I had to the of the--I, and, and I had to to the the of the the of the, and I had to the of the of the of the to the of\n",
      "Ep 4 (step 000030): Train loss 4.792, Val loss 6.393\n",
      "Ep 4 (step 000035): Train loss 4.382, Val loss 6.276\n",
      "Every effort moves you know the picture.    \"--and it a of the of the of the picture to me.     \"I it--and it to the picture to the picture to the of the picture of the of the of\n",
      "Ep 5 (step 000040): Train loss 3.822, Val loss 6.208\n",
      "Every effort moves you know it was not to have to have to see the fact of the last--his, and--his--and here are the sketch of the fact of his pictures--as, and in the sketch of the donkey.      \n",
      "Ep 6 (step 000045): Train loss 2.929, Val loss 6.175\n",
      "Ep 6 (step 000050): Train loss 2.457, Val loss 6.185\n",
      "Every effort moves you know,\" was not that my dear, and he had been the his last word. Gisburn's an!                           \n",
      "Ep 7 (step 000055): Train loss 2.111, Val loss 6.189\n",
      "Ep 7 (step 000060): Train loss 1.769, Val loss 6.271\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.        \"Oh, in the moment--as Jack himself, one might put it, had been the--because he's. The\n",
      "Ep 8 (step 000065): Train loss 1.161, Val loss 6.298\n",
      "Ep 8 (step 000070): Train loss 0.834, Val loss 6.317\n",
      "Every effort moves you?\"     I glanced after him, and uncertain.           He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 9 (step 000075): Train loss 0.550, Val loss 6.332\n",
      "Ep 9 (step 000080): Train loss 0.389, Val loss 6.454\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, my eye fell on a small picture\n",
      "Ep 10 (step 000085): Train loss 0.268, Val loss 6.491\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, moved aside a _jardiniere_ full of\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, test_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens sees\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAATuJJREFUeJzt3Qd8jPcfB/CPTBJJiCxBxCb2rtkqNaotOpSqKv/S2qq01aF0qVFVqoq2dFA6rKpZm9o7iC1IRKxEhuz7v76/y3O5RJBEknty+bxfr8fdPbd+98jd9/mt76+IwWAwgIiIiHTJxtIFICIiontjoCYiItIxBmoiIiIdY6AmIiLSMQZqIiIiHWOgJiIi0jEGaiIiIh1joCYiItIxBmoiIiIdY6AmsgIXLlxAkSJFcOjQIUsXhYhyGQM1kU5IoL3fNm7cOEsXkYgswM4Sb0pEd7ty5Yrp+uLFizF27FicPHnStK948eIWKhkRWRJr1EQ64ePjY9rc3NxULVq77eXlhalTp6Js2bJwdHREvXr1sGbNmnu+VnJyMvr164fq1avj4sWLat/y5cvRoEEDFC1aFBUrVsT48eORlJRkeo683/fff49u3brByckJVapUwYoVK0z337p1C7169YKnpyeKFSum7p83b949y/Dnn3+idu3a6rGlSpVCu3btEBMTY7pf3qtGjRqqPFLOb7/9Nt3zL126hO7du6NEiRJwd3dHly5dVBO/ZvPmzWjSpAmcnZ3VY1q0aIHg4OAcHHkinZPVs4hIX+bNm2dwc3Mz3Z46darB1dXV8NtvvxmCgoIMb7/9tsHe3t5w6tQpdf/58+dlFTzDwYMHDXFxcYZu3boZ6tevbwgPD1f3b926VT1//vz5hrNnzxrWrVtn8Pf3N4wbN870HvL8smXLGhYuXGg4ffq0YdiwYYbixYsbbty4oe4fPHiwoV69eoa9e/eq91u/fr1hxYoVmZY/NDTUYGdnp8otjz1y5Ihh5syZhqioKHX/r7/+aihdurThr7/+Mpw7d05duru7q/KJhIQEQ40aNQz9+vVTzz1+/LjhpZdeMlSrVs0QHx9vSExMVMdn1KhRhjNnzqj75bnBwcF5+L9CZBkM1EQFIFD7+voaPvvss3SPady4sWHQoEHpAvW2bdsMbdu2NbRs2dIQERFheqzs+/zzz9M9/5dfflHBUiPP/+CDD0y3o6Oj1b7Vq1er208//bShb9++WSr//v371XMvXLiQ6f2VKlVSJwTmPvnkE0OzZs1MZZOgnJKSYrpfAnSxYsUMa9euVScP8vqbN2/OUnmICjL2URPp3O3btxEaGqqads3J7cOHD6fb17NnT9U8vnHjRtXkrJHH7dixA5999lm65vG4uDjExsaqpm5Rp04d0/3SpOzq6orw8HB1e+DAgXjuuedw4MABtG/fHl27dkXz5s0zLXPdunXRtm1b1fTdoUMH9fjnn38eJUuWVM3fZ8+exf/+9z/079/f9Bxphpcmf628Z86cgYuLS7rXlfLKc+X1Xn31VfXaTzzxhGpWl2by0qVL5+gYE+kZ+6iJrMiTTz6JI0eOYOfOnen2R0dHqz5pmb6lbUePHsXp06dVH7HG3t4+3fOk3zolJUVd79Spk+oDfvPNN9WJgwTiUaNGZVoOW1tbrF+/HqtXr0ZAQABmzJiBatWq4fz586osYu7cuenKExgYiF27dpnK27Bhw3T3y3bq1Cm89NJL6jHSPy6fU04WZPBd1apVTc8nsiqWrtITUc6bvqXfOGMf9fTp0w3Ozs7pmoWbN2+u+nvvR56/dOnSdPukDFKWzHz33XcGFxeXLH2epKQkQ5kyZQxffvml6fN8/PHH93z8nDlzDCVLljRERkYasuqRRx4xDB06NMuPJyoo2PRNVACMHj0aH330ESpVqqRGfEttUmqYCxYsuOuxQ4cOVc3aTz31lKrRtmzZUk31ktt+fn6qCdrGxkY1L0st9tNPP81SGeQ1pJZbs2ZNxMfHY+XKlWrUdmZ2796NDRs2qCZqGbEut69du2Z6vNTuhw0bppq6O3bsqF5v3759amT5yJEj1ejyyZMnq5HeH3/8sWrOl9r8kiVL8PbbbyMxMRFz5szBM888A19fXzWNTVoHXnnllYc80kQ6ZOkzBSJ6cI06OTlZjdCWWqmM9q5bt65pkFfGGrVGaq9S492xY4e6vWbNGlWzlgFZMgK8SZMmquaa1Rq1DPaSkdjyfBmh3aVLFzViOzMyCrtDhw4GT09Pg6Ojo6Fq1aqGGTNmpHvMggUL1ChyBwcHVXtu3bq1YcmSJab7r1y5YnjllVcMHh4e6jUqVqxo6N+/v6plh4WFGbp27aoGw8nzy5cvbxg7dqw6TkTWpoj8Y+mTBSIiIsocB5MRERHpGAM1ERGRjjFQExER6RgDNRERkY4xUBMREekYAzUREZGOMVDfw8yZM+Hv76/SKzZt2hR79uyxdJF0YevWrXj66adVkglJL7ls2bJ098tsP0mMITmXJde05GCWRBTmbt68qRJaSB5pWZ5Qcj5raSU1kgazVatW6viXK1cOkyZNuqssf/zxh1oeUR4jOaVXrVqFgmzChAlo3Lixym8tSUIkl7b5etRaruvBgwerZSNlfWrJvX316tV0j5FlLTt37qzyd8vrSLIU8+UstSUiZclLWTKzcuXKmD9/fqH4DsyaNUvlM5e/PdmaNWumksJoeHxz1xdffKF+J0aMGGHax2OcA5aeyK1HixYtUkkUfvzxR8OxY8dUkoUSJUoYrl69aijsVq1aZXj//fdVYorMEmR88cUXKknGsmXLDIcPHzY888wzhgoVKhju3LljekzHjh1Vwo5du3ap1Z4qV65s6Nmzp+l+SWjh7e1t6NWrlyEwMFAt7ShJNmbPnm16jCTxsLW1NUyaNEkl15BVnyQRyNGjRw0FlSQIkeQi8pkPHTpkePLJJw1+fn5qFSvNG2+8YShXrpxhw4YNhn379qm0mZLExDxVZ61atQzt2rVTyU/k/0sShowZM8b0GElS4uTkZBg5cqQ6dpKIRI6lJESx9u+ALMv5zz//qOVBT548aXjvvffU340cc8Hjm3v27NmjllKtU6eOYfjw4ab9PMbZx0CdCcnYpOVQFpLtSHITT5gwwaLl0puMgVqWJPTx8TFMnjzZtE+WWpSsUhJshXyp5HmyprFGMmwVKVLEEBISom5/++23KlOVLGuoeeedd9Syh5ru3bsbOnfunK48TZs2Nbz++usGayFrScux2rJli+lYSlD5448/TI85ceKEeszOnTvVbflRs7GxUZm7NLNmzVKZyLTjKWtZ16xZM917vfjii+pEoTB+B+Rv7fvvv+fxzUWy7niVKlXUmuWPPvqoKVDzGOcMm74zSEhIwP79+1WTrUbyIsvtjCsSUXqyMlJYWFi6Yye5nKXJSTt2cinN3Y0aNTI9Rh4vx1jyQWuPad26NRwcHEyPkeUMpRlYckFrjzF/H+0x1vR/FBkZqS7d3d3VpfxdSo5r888tTf+Sv9v8+Eo3gLe3d7rjIktlHjt2LEvHrrB8ByQf+qJFi9Sym9IEzuObe6RpW5quMx4HHuOc4aIcGVy/fl19gc3/SITcDgoKsli5CgIJ0iKzY6fdJ5fS52TOzs5OBSPzx1SoUOGu19DukzWN5fJ+71PQydKS0q8na07XqlVL7ZPPJicvcqJzv+Ob2XHR7rvfY+SH8M6dO+pkyJq/A7K8pwRm6SuVPtKlS5eqpThlkRMe34cnJz+yZvnevXvvuo9/wznDQE2k0xqJrGy1fft2SxfF6si62BKUpcXizz//RJ8+fbBlyxZLF8sqXLp0CcOHD1drkZuvc04Ph03fGXh4eKhF7zOOQpTbPj4+FitXQaAdn/sdO7kMDw9Pd7+M5pSR4OaPyew1zN/jXo+xhv+jIUOGqCUkN23apJZ31Mhnkya9iIiI+x7fnB47GQUtI/Wt/TsgNToZJSxLdspI+7p16+Lrr7/m8c0F0tws328ZjS0tZbLJSdD06dPVdanR8hhnHwN1Jl9i+QLLWrrmzZByW5rL6N6kuVq+BObHTpqipO9ZO3ZyKV9S+UJrNm7cqI6x9GVrj5FpYNKXpZEzdKkJSbO39hjz99EeU5D/j2R8ngRpaYqVY5Kx+V/+Lu3t7dN9bum3l6ks5sdXmnbNT4bkuMgPmDTvZuXYFbbvgHw2WQ+bx/fhtW3bVh0fabHQNhmPItMxtes8xjmQw0FoVk2G9ctI5fnz56tRygMGDFDD+s1HIRZWMppTpkzIJn8+U6dOVdeDg4NN07PkWC1fvtxw5MgRtWZxZtOz6tevb9i9e7dh+/btanSo+fQsGRkq07N69+6tps3I/4dMxcg4PcvOzs4wZcoUNWr0o48+KvDTswYOHKimtm3evFmtxaxtsbGx6aa2yJStjRs3qqktzZo1U1vGqS3t27dXU7xkuoqsCZ3Z1JbRo0erYzdz5sxMp7ZY43fg3XffVaPoZf1u+fuU2zLjYN26dep+Ht/cZz7qW/AYZx8D9T3IvDz5Y5J5eDLMX+b8ksGwadMmFaAzbn369DFN0frwww9VoJUvSdu2bdV8VXM3btxQgbl48eJqykXfvn3VCYA5mYPdsmVL9RplypRRJwAZ/f7774aqVauq/yOZqiHzYwuyzI6rbDK3WiMnPIMGDVJTiuSHqlu3biqYm7tw4YKhU6dOau65zD996623DImJiXf9P9arV08du4oVK6Z7D2v+DvTr189Qvnx59Znkx1/+PrUgLXh88z5Q8xhnXxH5Jyc1cSIiIsp77KMmIiLSMQZqIiIiHWOgJiIi0jEGaiIiIh1joCYiItIxBmoiIiIdY6C+D8lWNG7cOHVJuY/HN2/x+OY9HuO8xeNrxHnU9yHpL2WZRkneL+nrKHfx+OYtHt+8x2Oct3h8jVijJiIi0jEGaiIiIh2z+vWoZQnFgwcPquXVbGyyd14SFRWlLkNCQlQTDOUuHt+8xeOb93iM85Y1H9+UlBS17Gb9+vXVEqD3Y/V91Hv37kWTJk0sXQwiIqK77NmzB40bN0ahrlFLTVo7GKVLl7Z0cYiIiHDlyhVVidRilG4D9datWzF58mTs379fFXrp0qXo2rWr6X6p7H/00UeYO3cuIiIi0KJFC8yaNQtVqlTJ8ntozd0SpMuWLZsnn4OIiCgnstIla9HBZDExMahbty5mzpyZ6f2TJk3C9OnT8d1332H37t1wdnZGhw4dEBcXl+9lJSIisgSL1qg7deqktsxIbXratGn44IMP0KVLF7Xv559/Vs0Ey5YtQ48ePfK5tERERPlPt9Ozzp8/j7CwMLRr1860Tya+N23aFDt37rRo2YiIiPKLbgeTSZAWGTva5bZ2X2Yk1Zx5ujlteD8RUVYkJycjMTHR0sWgAs7e3h62trbWHahzasKECRg/fryli0FEBYx0t0klQAauEuWGEiVKwMfHB0WKFLHOQC0fTsiEcPNpVXK7Xr1693zemDFjMHLkSNNtmSgfEBCQO4VKTgL+/Qio0Bqo2iF3XpOIdEEL0l5eXnBycnroH1cq3Cd9sbGxCA8PV7cfdmqwbgN1hQoVVLDesGGDKTBLZhoZ/T1w4MB7Ps/R0VFtmtzMZpO853vY7vwG2P8T8Np6wKtGrr02EVm2uVsL0qVKlbJ0ccgKFCtWTF1KsJa/q4dpBrfoYLLo6GgcOnRIbdoAMrl+8eJFdTY7YsQIfPrpp1ixYgWOHj2KV155Bb6+vunmWueXmzEJ6H04APsRACREAb/1AGJu5Hs5iCj3aX3SUpMmyi3a39PDjnmwaKDet2+fynMqm5Ama7k+duxYdfvtt9/G0KFDMWDAAJViTQL7mjVrULRo0XwvazF7W9yKL4LX4obhqo03cOsC8PsrQFJCvpeFiPIGm7tJj39PFg3Ujz32mGrLz7jNnz/f9CE//vhj1XckSU7+/fdfVK1a1SJlLeZgi+9eboDkou7ofWck4m2KAcHbgdWjpUPCImUiIiLrp9t51HpUvpQzvu5RH6dRDgPjBsOAIsD++cCeuZYuGhFRrvH391cJp7Jq8+bNqmKV1yPm58+fr0ZSFzYM1NnUproXhretgo0pDTA5+SXjzjXvAmc3WrpoRFTISHC83zZu3LgcrzooXY5Z1bx5c7VegySlotyn21Hfejbs8So4cjkS3wY9idoOIeiUvBn441XgtY2AR2VLF4+ICgkJjprFixer8T0nT5407StevLjpunQryuj2B619LDw9PbNVDgcHB9OUWsp9rFHngI1NEXzVvR783J0xIuZVnHYIAOIigd9eBO7csnTxiKiQkOCobVKblVq0djsoKAguLi5YvXo1GjZsqKatbt++HWfPnlXrJ0iWRwnkMlBXxv/cr+lbXvf7779Ht27d1EhmWcFQZuPcq+lba6Jeu3YtatSood6nY8eO6U4skpKSMGzYMPU4mRL3zjvvoE+fPtme1TNr1ixUqlRJnSxUq1YNv/zyS7qTE2lV8PPzU59fZg3Je2q+/fZb9VlkgLIcj+effx56xECdQ25O9pjduyGK2BfFS7eH4LaDN3DjDPBHX2NiFCIq+EkrEpIsssl755Z3330XX3zxBU6cOIE6deqo2TNPPvmkylFx8OBBFUCffvppNS32fiTjY/fu3XHkyBH1/F69euHmzZv3fLwk/JgyZYoKnLKksbz+qFGjTPdPnDgRCxYswLx587Bjxw6V80IWXMqOpUuXYvjw4XjrrbcQGBiI119/HX379sWmTZvU/X/99Re++uorzJ49G6dPn1avX7t2bdOsIwnaMmBZWiFkRlHr1q2hR2z6fgg1Srvii2frYMTiQ+gZNRwrnD6B7aU9QPhxoHQdSxePiB7CncRkBIxda5H3Pv5xBzg55M7PswSiJ554wnTb3d1dLS+s+eSTT1TAkxrykCFD7vk6r776Knr27Kmuf/7552oJ4j179qhAnxmZOyxLFEttV8hrS1k0M2bMUJkkpZYuvvnmG6xatSpbn23KlCmqXIMGDTJN8d21a5fa36ZNG3VyIK0LsriT5N6WmnWTJk3UY+U+WTr5qaeeUi0P5cuXN00V1hvWqB9S1/pl8Gpzfxwz+GNY0jCEPLeMQZqIdKNRo0bpbkuNWmq20iQtzc7SLC217QfVqKU2rpEA5+rqakqRmRlpIteCtJZGU3t8ZGSkSgetBU0hmbukiT47Tpw4gRYtWqTbJ7dlv3jhhRdw584dVKxYEf3791cnJNLkLuTkRYKz3Ne7d29Vu5dWAD1ijToXvPdkDQSGROKf4Lo4szoOSysmGc+GU1KkQ9vSxSOiHCY5kpqtpd47t0hQNSdBev369arWWblyZZXqUvpmExLun7xJaqTmpE86RX7jsvH43GzSz4py5cqpZm3pg5fPLDXvyZMnY8uWLaoWfeDAAdW/vm7dOjUQT/qzZcS73qaAMYrkAgc7G3zbqwE8XRxx8moU3vnrKAwXdwOzmgE3z1u6eESUAxJY5ITbElteZkiT/mBpLpYmZ+mvlabhCxcuID/JwDcZvCVBUSMj0iVwZkeNGjXU5zEnt80XYpITEemDl6Z6Cco7d+5UKamFjICXZvFJkyapvnc5Dhs36m+qLWvUucTLtagK1j3n7MLfh0Pw/tUp8IkIAjZ+Ajz/o6WLR0SkyCjnJUuWqOAlJwQffvjhfWvGeUXSQ8uyxFKrr169uuqzvnXrVrZOUkaPHq0GuEnfsgTcv//+W302bRS7jD6XE4CmTZuqpvhff/1VBW5p8l65ciXOnTunBpCVLFlS9Y/LcZCR43rDGnUuauzvjg86y4paRdAt/DVcrdoTeHq6pYtFRGQydepUFZgkSYkE6w4dOqBBgwb5Xg6ZjiWD02SxpWbNmqm+cilLdtZy6Nq1K77++mvVjF+zZk01ultGkUt6aiFN2HPnzlX91tLHLgFcgrlMB5P7JKg//vjjqmYuA99+++039Tp6U8SQ350G+ezy5cuqn+LSpUsoW7Zsnr+fHM43Fx/CskOh8CjugJVDW8HHLf8XESGirJO1BGT1Plle1xKL/pAM6UlRAVNqyDIS3dr/ri5nIzaxRp3LpNlmwrN1UN3HBdejEzBwwX4kJCYD274EDi6wdPGIiHQhODhY1XZPnTql+owHDhyogtpLL6WmZiYTBuo8WmlLkqG4FrXDwYsRWLJgJrDhY2DlCODiLksXj4jI4mxsbFQfsmRGk6ZpCdbSNC21akqPgToPV9qa1qOeuj4mqAJCfNoByQnA4peBiPvPVyQisnbS7CsjtGVOtWQl+++//3SbGczSGKjz0OPVvdVKWwbYoPPll3HHPQCIuQb89hIQH23p4hERUQHAQJ3HJFC3qeaJiCQHvBw7AilOnsDVo8DS140JUYiIiO6DgTofVtqa9mJ9+Lk7YX9EcXzq8gEMtg5A0Epg8+eWLh4REekcA3U+rbT13csNUdTeBj8Ge2JNhTHGO7ZOBo7+aeniERGRjjFQ55MAX1dMeNa4vNrAwGq4UK2/8Y5lg4DL+y1bOCIi0i0G6nzUrX5ZtdKW6HKyLWL9ZSR4PLDoJeB2qKWLR0REOsRAbYGVthqVL4nIuBT0utkfKR7VgegwY7BO0OcSa0Rk3STl5ogRI0y3/f39MW3atAcmd1q2bNlDv3duvc79yKpY9eoZp8sWRAzUFlxp62B4Mj5xGQtDMXcgLBC4vMfSxSOiAkRydXfs2DHT+7Zt26aCoKwKlV2yqtWAAQOQH8HyypUr6NSpU66+l7VhoLbgSlt2NkUw7wSwKmAy0GcFUNGYSJ6IKCv+97//qXWWJW90RrI4RaNGjdRiFNnl6empVpvKD7LMpqOjY768V0Gl60Aty5PJEmyS0FyWJqtUqZJK1m4N64jISlvvq5W2gGE7nbA72WxptcjLQHKi5QpHRAXCU089pYKqpOI0Fx0djT/++EMF8hs3bqhVqsqUKaOCr6xBLatE3U/Gpu/Tp0+rrGGysISs9SwnB5mthlW1alX1HhUrVlS/3YmJxt8xKd/48eNx+PBhVcuXTStzxqZvSSUqK1rJb76scjVgwAD1eTSylrasmiUrZpUuXVo9ZvDgwab3yuoCIB9//LFaDENOEqSmv2bNGtP9CQkJGDJkiHp9+cyyLKYsySkk/kjrgJ+fn3qur68vhg0bhkK7HvXEiRMxa9Ys/PTTT2rpsX379qFv375q0fG8PjD5QQaWHboUgeWHQjF44UH8M6wlvBNDgPlPAeUaA8/9ANjaW7qYRIVbQkz2n2PrCNim/rwmJxkHjRaxAeyLPfh1HZyz/DZ2dnZqmUgJeu+//75pLWcJ0lLRkQAtQa5hw4YqkLq6uuKff/5B7969VcWnSZMmWQpqzz77LLy9vbF7926V8tO8P1vj4uKiyiGBS4Jt//791b63334bL774IgIDA1Uw1NaKlt/xjGJiYtRSl7LspTS/h4eH47XXXlNB0/xkZNOmTSqIyuWZM2fU60uwlffMClka88svv1TLYspa1j/++COeeeYZHDt2TK3XPX36dKxYsQK///67CsiywpVs4q+//sJXX32FRYsWqbgUFhamTkAKbaCW3K9dunRB586dTWd5cia4Z88eK1ppqzZOhkUhKCwKA37Zj8VtY1A09jpw7SQQHwU4uVu6mESF2+e+2X/OC/OBmt2M14P+Bv54FSjfEuj7T9pjptUGYm/c/dxxkdl6q379+mHy5MnYsmWLaR1mafZ+7rnnVDCUbdSoUabHDx06FGvXrlVBKCuBWgJrUFCQeo4EYfH555/f1a/8wQcfmK7Lb7W8pwQzCdRSO5b1puXEQpq672XhwoVqaciff/4Zzs7GE5ZvvvlG9cVLxU1OFoSspy37bW1tUb16dRUjNmzYkOVALbVxOXHp0aOHui2vLUFfWhFmzpyJixcvqoDdsmVL9TstNWqN3CefoV27drC3t1eBPCvH0WqbvmVhczn4sgyakLOW7du3W9XAAycHO7XSVgknexy+FIHBu0oiuefvQJ+/GaSJ6IEkUMlvpdQKhdQwZSCZNHsLqVlLl6E0ebu7u6uAKUFXAk5WnDhxQi2goQVpITXejBYvXqxWwZIgJu8hgTur72H+XnXr1jUFadGiRQtVqz958qRpn9RkJUhrpHYtte+skAVAQkND1euak9vy/lrz+qFDh1CtWjXVertu3TrT41544QXcuXNHNe/LicHSpUuRlJSEQlujfvfdd9VBlT9E+U+RP7jPPvsMvXr1uudz4uPj1aaJiopCQVhp64c+jfDS3N3YEBSOD1zL4fNKnjA2YgE4txko34LN4ESW8F5ozpq+NdWfNr6GNH2bG3EUuUWCstSUpTYotWlp1n700UfVfVLblqZeqS1KsJYgKE3X0g+bW3bu3Kl+l6UfWpqupRYvtWlpXs4L9vbpfwul1ivBPLc0aNBArY29evVq1aLQvXt3VYP+888/1UmLnDTIfumrHzRokKlFI2O5CkWNWppmFixYoJpDDhw4oPqqpclCLu9FOvy15h7ZZOBDQdCwvDum96wPmyLAb3suYcbGM8Y7Dv4K/NwV+Os1DjAjsgTpM87upvVPC7ku+8z7p+/3ujkggUTWd5bfSmk2luZwrb9alpKULsSXX35Z1ValJqi1UmaFrA8t/bMyjUqza9euu7oppXlY+sllpLk0GwcHB6f/uA4OqrL1oPeSllPpq9bs2LFDfTap3eYG6aeX1gF5XXNy2zxeyOOk73vu3LmqtUD6pm/evKnuk6Z8aY6XvuzNmzerExXpl88rug7Uo0ePVrVq6UeQM0EZAPHmm2+aRt9lZsyYMWqwg7YdP34cBUWHmj4Y36WWuj51/Sn8vvcS4ORhrEkfX8ZgTUSZkqZmCSry+ycBVZpuNRI0peYnwVSadl9//XVcvXo1y68tNUkZzd2nTx8VRKVZXQKyOXkPaeaWWvTZs2dVAJMmYXPSby21VGlSvn79erqWT43UymWUtbyXDD6TfuOhQ4eq336tfzq3Yov0S0sAltqxxBkp1/Dhw9X9U6dOVeOhpG9eTmpkcJ406ZcoUUINavvhhx9U+c6dO4dff/1VBW7zfuxCFahjY2PVmZQ5aQK/XxOHDJeXMyFtk1GHBUnvR8pjcJtK6vqYpUexCQ2A7r8AsuIWgzUR3af5+9atW6rp2bw/WfqKpSlX9stgMwk4Mr0pq+Q3WIKu9MvKoCkZhS1dkOZkxLRUomR0toy+lpMCmZ5lTga3SXKWNm3aqCllmU0Rk6ld0n8uNdfGjRvj+eefR9u2bdXAsdwk/c4jR47EW2+9pSqBMhpdRnnLCYeQuDFp0iTVOiDluHDhAlatWqWOhQRrqWVLn7bMUZcm8L///ltNE8srRQw6npQsZ4VyEGQIvQweOHjwoJpTJ806cjaUFZIIQPoUpOlG5swVBPJf8tYfh7HkQAiK2dti0YBHUDd2F/B7byA5AQjoCjz3PfusiXKJjDSW2p7kbJAaHVFe/11lJzbpukY9Y8YMdUYlnfXSdyHD/aXZRkYwWjPpW5r4XB20quKBO4nJ6Dd/L4I9WrFmTURUCOk6UEvzg4xUlEEJ0uwifR+ffvqpGpRg7extbTDr5Yao6euKGzEJ6PPjHtwo04bBmoiokNF1oC7sijvaYV7fxihbshgu3IhFv5/2IbZCOwZrIqJChIFa57xciuKnfk1MCVGGLDyIpMrtGayJiAoJBuoCoJJncfzQpzEc7WywMSgcHy4PhKFqh7uDdS5O+CciIn1goC4gGpYvmS4hyvQNZ4BqHdOCtXdNmUdh6WISFWi5md2KKCWX/p50nUKUMk+I8uGyQHz17yn4uDnixcYdgUG7gFLGuddElH0yQFXmyEoOaJnjK7e1zF5EOZliKylar127pv6uHnYANAN1ASMJUcIi72DmprN4b2mg6sNuU90sSMdHA7u+BVq+yXnWRFkkP6Yy11WyekmwJsoNksBFVtfKmLgruxioC6BR7avhSmScSogyaMEBY0KUciXkNA5Y/DJwbhMQcRHokrvZfIismdR65EdVVkJ6UE5qogeRLJqyrGdutMwwUBfghCjXouKx7fR1lRBlyaDmahUuNH0DCDsKNOxr6WISFcjvlqyAlFerIBHlBEcfWUlClFd+3IPr0fHGAWYjjgBlG1q6iERElAsYqK0kIUrwjVj8b/5exCYkpV8qL2Q/sHwIEGtcno2IiAoWBmprSohyOdKYECU5dUpAQgyw8EXg4C/AlCrAL92A/T8BMTcsXWwiIsoiBmorTIjywbJANT1A1ay7zQa8awMpScDZjcDfw4xB+6dngH0/AtHXLF18IiK6DwZqK0yIsmjvJXy94bTxjsptgYHbgSH7gbZjgdJ1AUMycH4LsPJN4MuqwPyngD1zgagwS38MIiIqSOtR54aCuB71w/h1V7CqUYuJz9XGi4397n7QzXPA8RXA8eVA6AGzO4oAfs2A7j8DxT3zr9BERIXMZWtZj5qy7+VHymNwG2MCFEmIsjHo6t0Pcq8ItBwBDNgEDD8CtP8UKNNI8ukAty4ATqXSHnt2ExB5OR8/ARERmWOgttKEKM82KIPkFAMGLzioVt26p5LlgeZDgf4bgBGBwLNz0nKGJycZF/v4qiZwaU++lZ+IiNIwUFtxQpRWVTxwJzFZJUTZeuqacYDZ/ZQoB1RolXY75hrgWQ1w8gB866ft3z0H2P6VsQmdiIjyFPuorVh0fBJenL0Tx0Jvq9uPVHTH2x2ro4Ffyey9kEzz0uZmy5/LtNpA5CXjbTc/wLU04OIDuJQGinsbL9Xt1K1oCTl7yO2PR0RUKGITA7WVi4xNxPSNp/HLzmAkpM6vblfDG6M7VEM1H5fsv2ByInDwV+Ma2Oe3GUeQP4hdUeCpaUC9nmaD2ZYDHlWB6p2zXwYiokIUm5jr28q5Odnjw6cC0K9lBXz97yn8uf8y/j1xFRuCrqJbvTJ484mqKOfulPUXlBW5GvU1bpLt7PppIOoKEH3VeBmlXYYB0WHAnVtAUhzgWDztNUIPAf+OM44wNw/U0+sDhpS0mnmxEoBDccDR1fh8dd0lbZPb0lxf1C13DxoRWafkROPvkY09YF80rcVQfseS4oHkeOOl2uKA5ATjZVLqpfw21X0x34vNQF1IlClRDJOer4sBrSth6vqTWHU0DEsOhuDvI6Ho2cQPQx6vrLKcZYuTO+DX9P6PSYwzBmzzkeTyx16nB1Cqctq+lGTgVrCxhi4jz7Oqy0yg/svG65LQRQa/lW0CvLQo7TGr3gaS7hgDvgR3aca3LwbYOhhr+3aOqZdmt0uUB5w90r7ciXfSHkNElpMUD0SHp25Xjb8vpuvhxkpCXERacB15PG3J36VvAIF/Ah0mAM0GGffJIkY/dsjae5d7hIGa8l5lr+L4tldDHLkcgclrT6rVt37eGYw/9l1Gv5b+KpC7FcvFlYPkrLWkf/p95ZsZN3NFbICh+9Nq4lIzj7+dukUDCdFAfFTq9ai068XM+tvvRACxN4z3mZMvpuzPjk6TgKavG69f3gvM62Q8sZAyaiS7m5xUqECfGuyldu/sBRRP3cyvSyuB9Nc/5Nq0RFZHemDNx7HISffVY0CFR4HSddL2/dnP2EqX3cCuBWr5ngqpOWvkxN3F1+x77AjYOqb/Xmsn9R5mlYt8xEBdSNUpWwK//K8p/jtzHRPXnlRTuGZuOotfd13EG49WwqvN/VHMwTb/CiRfUvcKxi2nqjwBDNoFFMlQ7sfGGIO4BH0V8KNTm7i0Zq2MzVzxxoCqkX1CvqjmbocAEcHZK2Prt4HH3099fiiw8TOghB/w2Dtpj4kMMdb45SSEg/DoXoFNWnrkbzZFLpOMrVGSKlg2YX6CHB5kPIGVQKOd3Mrfn9Qm1XO055q9hun15DLZeFtOqJsNTnvdw4uB6yeB6k8BZRqkvtcJYO/3aa8l3Vna880vpfwys0RqwXduAmMuAzap390DPwPHlgIdJ6YFamkN04K0NF2rgavexkvtRFjb5DNKJUECrnyXNJ2/NG6yX+NTG3jrBPSMgbqQa17ZA8sqlcK641cxZe1JnA6PxsQ1QZi34zyGta2CFxuXU0tqFgjSb+1V4+79Tfo/3OtWbAO8f9X4g2juxQXGwK+Ce2qAlx8S+eFRP0CpTXHqtvwY3QKczTK+SVP/oV+NCWjMA/Wil4Arh4w/RvJ4VTP3NNbWpa9e9dGnNuOr68UB71qARxXj8+VHW1odHFwAW37F842cDMr/dVyksenV/FI7UVT9oImpwTXReJLWaWLaa/zWE4i4aMzR71PLuE+CnpzQSdDTgvODBnG6ljE2+WqWDwZC9gE9FwHVOhn3nd8KLE1tNcoqqVmaB2oJpqdWG7uKtEAtJ7BS5uySMS9aRsTyLYx///Ld0MjfuJyIa4E4Jyex5kG7AOG3mNS86w41fdRo8GUHQzB1/SmERNxRqUjnbjuHkU9UxdN1fGEjicQLI/lBUANPMtSovapn73WkBi+1C42rL/D4h4B9hsF88mMu5Mc8KtS4PUibD4BHRxuvSw1nVnNjcB99Ju0xK4YBN86aBfvUAXnS9Cc/wKp5T5r97I01Drn0rJ4WMKRcUgOTx0gtRBMn0/8Mqc9xyFnTvtQQ5dhIjU37AZbxDXIMZL92v+lSjqNc1yatpF6XVg9ns/EQEvTksa5l005aZPU4CaDquYa7L+WkSwuuKthGGk+W6vZIe92fnjZ2z7z8l3FAo5DcAjumZe9zS/Axd+0kcPNs+u4bOfGSGueDSEuS1Eht7O5u/ZEplDHljf8/Gi0/gnqeXepm9hqyyf+Htl8eZ/58Ua2jMWmS+QmyBFdpOVLPk//P1Nc0L5+8rvx9SRm0mrGMeTE/uc54gu3glPmJeCGg+0AdEhKCd955B6tXr0ZsbCwqV66MefPmoVEjSXlJucnWpgiea1gWT9Utjd92X8Q3m86oda6HLzqE77acw+gOVdGmmpcK7JQDGQeiyQ9c61F3P27wLmNQNNXKrxmvq375qPR99Op2dPouA9kvJAibCz0IhB3JXpmbD0sL1DKa//u2xhOL96+kPUb6Dc+sT7stP8Qq8Eu/YJH0wVULsPVeAp76yvh4CYgTyxuvf3At7TitGAIc/SN75a3aKf1AwukNjMH+zWOAW+oUmG1TgF3fZu91ZYaCeaDWZjtIANUCtQQa6TKRlg9tk5kL6noJYyuInPBJTVGdDKUGKnPPzDB2y5ifBNZ+Aaj4aOpJkF3qcx3SH2cV/O7zvXzx17v3VWln3B5Gw1fv3ieBWuveIesP1Ldu3UKLFi3Qpk0bFag9PT1x+vRplCyZzYQdlC2OdrZ4tUUFvNConGoCn73lHE5cuY1+8/ehUfmSKmlKkwpmZ7+U+6TWKoFFCy7ZISPxP7wOJMam39/xC2Pg14K7KfDHpDWpSpBQU1jkMgEoZcwbr0jAlabajLU1eZw5rY8zQ0/BPZ8jtau0N7nH/oyKpAYm7TJ1n9bHaV4Lk89jTsovQVM9N5PXk2MvgdUUZN2MLQvmun5rDI7mTbMthhu3h+Hf4u590kJg3kpAhY6uE568++672LFjB7Zt25bj1yjsCU9yw62YBHy35Szm/3cB8UnGpts21TwxqkM11PTlHOZCTw1skoF4qUFem4uqBUitOVtdpm7S3K41daakGPvv5THmfY/yGqbmcPONLTpU8FlNZrKAgAB06NBBfaAtW7agTJkyGDRoEPr3v/fgoPj4eLWZN53L6zBQP7ywyDiV5Wzx3ktqwQ8h+cTr+5VELV9X1C7rBh/XomwaJyIqLIG6aFFjE9vIkSPxwgsvYO/evRg+fDi+++479OnTJ9PnjBs3DuPHj79rPwN17jl/PUYNOPv78N2DnEo5O6BmGTcVuGupSzeUcy/G4E1EZI2B2sHBQQ0a+++//0z7hg0bpgL2zp07M30Oa9T55/TVKOw4cx2BobcRGBKppnZpNW1zLkXtVMCuVcYYvKW5vIKHsxq8RkRUGF22llzfpUuXVkHWXI0aNfDXX3/d8zmOjo5q09y+bVw5inJfFW8XtWniEpNxMiwKgaGRCAy5jWOhkQi6EoWouCTsPHdDbRonB1sElNYCt/FSsqYVmDnbRET5RNeBWkZ8nzx5Mt2+U6dOoXz51KkcpCtF7W1Rt1wJtWkSk1Nw+mq0Ct7HQiJV7ft46G3EJiRjX/AttWkc7GxQw8dFNZ1L8K7m7YKKnsXh7sz82kRUeOk6UL/55pto3rw5Pv/8c3Tv3h179uzBnDlz1EYFg9SQA3xd1YZGxvmm0jx+/nq0qnVLk7kxiN9GVHwSDl+OVJu5kk72qORZ3Lh5OaOih1wWR7mSxWDHGjgRWbkc9VFLm7oMDtLa1SWALly4UDVTDxgwIFcLuHLlSowZM0bNn65QoYIaWHa/Ud8ZcXpWwZCSYsClW7HG4C2BO/Q2zoZHqwxp92JvWwT+pZxR0dPZLJAXV7ddi+biwiJERAVtMFmrVq1UQO7duzfCwsJQrVo11KxZUwXToUOHYuzYsdALBuqC7U5CMs5dj8bZazE4d814KQFc9sUlmqXjzMDTxRGVUgO4NJ9r12W5z0KbCpWICs9gssDAQDRp0kRd//3331GrVi2VmGTdunV44403dBWoqWCTFbxklHjGxCpSA79yO04F7bMqgEfjbHiMCuBXb8fjWpRx23UufY5kRzsb1f89vF1VPFrVbIEMIiKdylGgTkxMNI2s/vfff/HMM8+o69WrV8eVK2Y5gInyiNSKpXYsW+sMATcqLhHnpOZ9Ldp0KduF67Eqs9qBixHo8+MePBHgjQ87B8CvVIZFMYiICnqglmZuSTrSuXNnrF+/Hp988onaHxoailKlmJOWLMulqP1do89FUnIKLt+6g193Bat0qOuPX8WWU9fweuuKGPhYJTg56HpsJREVUjkaMjtx4kTMnj0bjz32GHr27Im6deuq/StWrDA1iRPpjYwQ9/dwxgdPBWDNiFZoWdkDCUkpmLHxDNp9uQUrj4RCx/l/iKiQynFmsuTkZJVMxHwlqwsXLsDJyQleXl7QCw4mo3uRP/21x67i03+Oq5q2eKSiO8Y9UxPVfWR1JSIiy8emHNWo79y5o9J0akE6ODgY06ZNU8lJ9BSkie5Hphh2rOWDf0c+ijfbVVUDzWTw2ZNfb8NHywMREZth+UYiIgvIUaDu0qULfv75Z3U9IiICTZs2xZdffomuXbti1qxZuV1GojzPqDa8XRVseOtRPFnbB5Ku/KedwWgzZTMW7r6Yaf5yIiJdB+oDBw6oudTizz//hLe3t6pVS/CePn16bpeRKF+ULemEb3s1xMLXmqKqd3Hcik3Ee0uPosvM7dgfnH6aFxGRrgN1bGwsXFyMizHI3Olnn30WNjY2eOSRR1TAJirImlf2wKphrfDR0wFq5S/JlvbcrJ14c/EhXL0dZ+niEVEhk6NAXblyZSxbtkx1gq9duxbt27dX+8PDw+HqykE4ZB0jxPu2qIDNox5Dj8blIMtpLz0YgsenbMZ3W86q0eJERLoN1JJ5bNSoUfD391fTsZo1a2aqXdevXz+3y0hkMaWKO+KL5+pg+eAWqO9XAjEJyfhidRA6TtuKTSfDLV08IioEcjw9S3J8SxYymUMtzd7a4hxSo5YMZXrB6VmUWyRtqdSqJ6wOwvXoeLWvbXUvfPhUgJqfTUSkm0U5Mr6Z0GsQZKCm3CYpSiVJyo/bzyMpxQAHWxu81qoCBrepDGdHZjcjIh3Mo05JScHHH38MNzc3lC9fXm0lSpRQqUTlPiJrT1H63pM1sGZEa5VnPCE5Bd9uPou2X27BL7uC1WIgRES5JUen/++//z5++OEHfPHFF2jRooXat337dowbNw5xcXH47LPPcq2ARHpV2as4furbGP+eCMcnK4/j4s1YfLgsEGOXB6JxeXd0qOWDDjW91bQvIqKcylHTt6+vr1qUQ1s1S7N8+XIMGjQIISEh0As2fVN+iEtMVot9/H04FIcvR6a7r1YZV3Ss6aOyoFX2Mk5rJKLC7XJer0d98+bNTAeMyT65j6gwZjd7rVVFtYVE3MG6Y2FYeywMe87fVPOwZZuy7hQqeTqjQ2rQrl3GTaUxJSLK9Rq1pAyVLWMWsqFDh6qR37t374ZesEZNlnQjOh7/nriKNYFh2HHmhurP1sha2u1reqvA3djfHbY2DNpEhcXlvB71vWXLFrUWtZ+fn2kO9c6dO9Ubrlq1ypReVA8YqElPo8U3nbyGtYFhag52bEKy6b5Szg54IsBb9Ws3r1QKjna2Fi0rEVnB9KzQ0FDMnDkTQUFB6naNGjUwYMAAfPrpp5gzZw70goGa9Nqnve30dVXTlhp35J1E030ujnZoU91LNY8/WtWTU76IrFC+zqM2d/jwYTRo0ECtVa0XDNSkd4nJKaovW4K29GuHm03vkqU3W1XxVEFbVvZycmDQJrIGeT6YjIhyj72tDVpU9lDb+Gdq4uClCBWwJXDLlC+pccv28d/H0LOJH15p7q/6t4mocGCgJtIRG5siaFi+pNrGdKqOoLAoFbCXHQpB8I1YzN56Dt9vP6/mZ/drUUE9jiPHiawbAzWRTkkArlHaVW3D21ZRA9B+3HFejR5fdTRMbXXKuqFvC390ru0LB7scJRokImsK1LLu9P1EREQgL0kmtDFjxmD48OGYNm1anr4Xkd5q2m1reKstKOw25u+4gCUHQ3DkciTeXHwYn68KQu9HyuOlpn7wKO5o6eISkaUCteT2ftD9r7zyCvLC3r17MXv2bNSpUydPXp+ooKju46qW3hzdoRp+23MRP+8MVgPQpq4/hW82nUHXer5qLW2piRNRIQvU8+bNgyVER0ejV69emDt3rpr+RUTGtbKHPF4FA1pXwurAK2o1L0lf+vu+y2prVrEU+rWsgMerezGZClEBViA6tQYPHqwSrLRr1+6Bj42Pj8ft27dNW1RUVL6UkchSpG+6S70yWDa4Bf4a2Byd65RWgXnnuRvo//M+tJmyWQVxSbhCRAWP7geTLVq0CAcOHFBN31kxYcIEjB8/Ps/LRaTHwWfaiPHQiDuqSVyaxmWK18crj6um8RcalcWrzf1RvpSzpYtLRFmUqwlPcptMBG/UqBHWr19v6pt+7LHHUK9evXsOJpMatWwaWckrICCACU+oUIpNSMKSAyGYt+M8zl6LUftkNle7Gt5qtLg0j3N6F1EhykyW25YtW4Zu3brB1jYt77FkPZMfFhsbGxWQze/LDDOTEQEpKQZsO3NdNYFvOXXNtL+6jwsGtK6IbvXLMGAT5SOryUzWtm1bHD16NN2+vn37quU033nnnQcGaSJKm94lecNlOxMejfn/ncdf+0NUQpWRvx/GskOhmPx8HXi7FrV0UYmoIAVqFxcX1KpVK90+Z2dnlCpV6q79RJQ1lb2K49OutTG6fXX8ujsY0zecxtZT19Bh2lZ81rW2GoxGRPpRIEZ9E1Huc3Oyx+A2lfHPsJaoVcYVEbGJGLzwAN5cfCjdal5EZFm67qPODeyjJnqwhKQUzNh4GjM3nUGKAfB1K4op3euieSUPSxeNCIU9NrFGTURqLvZb7avhjzeao3wpJ4RGxuGlubvx6crjau1sIrIcBmoiMpE52KuGtVLLaQpZqeuZb7bjWGikpYtGVGgxUBNROs6OdpjwbG380KcRPIo74NTVaHSduQOzNp9FsrSLE1G+YqAmokzJSl1rR7RG+wBvJCYbMHFNEHrM2YlLN2MtXTSiQoWBmojuu/DH7N4NMen5OnB2sMXeC7fQcdpW/L7vEqx8HCqRbjBQE9F9Scay7o3KYc2I1mjsXxIxCcl4+88jeP2X/bgRnZaul4jyBgM1EWVJOXcnLBrQDO90rA572yJYd/yqSpKy4cRVSxeNyKoxUBNRlsnymQMfq6SW1KzqXRzXoxPwv5/2YcySo4iJT7J08YisEgM1EWVbTV83rBjSEq+1rKBuy3KaT07fhv3BtyxdNCKrw0BNRDlS1N4WHzwVgIWvNVWZzIJvxOKF7/7Dl+tOIjE5xdLFI7IaDNRE9FCaV/bA6hGt1VKZMs16xsYzePbb/9QqXUT08BioieihuRWzx1cv1sM3L9VX14+GRKLz9G2YvDYI56/HWLp4RAUaAzUR5Zqn6viqJCmtqnggPikFMzedRZspm/Hstzvw665gRMZyVS6i7OLqWUSU6+RnZXVgmEqMImtda5lHHWxt0C7AC8/WL4tHq3nC3pZ1BSqcLmcjNtnlW6mIqFAlSXmydmm1hUfFYcWhUPx1IAQnrtzGqqNhanN3dsAzdX3xXIOyaj1seQ4R3Y01aiLKN8dDb2PpwctYejAU182ymlXxKo5nG5RF1/q+KO1WzKJlJNJbbGKgJqJ8l5Scgm1nrmPJgRCsOxam+rOFVKpbVPLAsw3KoGMtHzg5sNGPrBMDtRkGaiJ9ux2XiNVHr6im8T3nb5r2OznYolOt0niuQRk8UrEUbGzYNE7Wg4HaDAM1UcFx8UYslh4MwZKDl1UCFY0kVOlav4xqHq/sVdyiZSTKDQzUZhioiQoe+Vk6cPGWqmWvPByK23FpecTrlnVTyVUer+4Nv1JOFi0nUU4xUJthoCYq2OISk7ExKBxLDlzGppPXkKzN9QLg5+6EllU80KqyB5pX8oCbk71Fy0qUVQzUZhioiayHjBSXqV6rA6/g4MUIJJkFbenCrl22hAraknClvl9JONhxnjbpEwO1GQZqIusUHZ+EXWdvYPuZ69h2+hrOXkufqlQGo8kgtJapgVv6tjlXm/SCCU+IyOoVd7RDuwBvtYnQiDsqaG8/fR07zlzHjZgE1WQum/BxLYoWqUFbLj1dHC38CYiyRtc16gkTJmDJkiUICgpCsWLF0Lx5c0ycOBHVqlXL8muwRk1U+KSkGHAi7LYK2hK8ZdqXNldbU93HBa2reqoad5MK7mrZTqL8YjVN3x07dkSPHj3QuHFjJCUl4b333kNgYCCOHz8OZ2fnLL0GAzURyYC0fRduqSbybaev4/iV2+nul77sxv4l0bKyp6pxB5R25bxtylNWE6gzunbtGry8vLBlyxa0bt06S89hoCaizAalSfO4VuO+EhmX7v6STvZqne2WqVs5d04Do9xltX3UkZGR6tLd3d3SRSGiAsyjuCO61CujNqmryEC07aevqaC969xN3IpNxD9HrqhNlC/lpPq1JWg3r1QKJZwcLP0RqBApMDXqlJQUPPPMM4iIiMD27dvv+bj4+Hi1aUJCQhAQEMAaNRFlSWJyCg5filBBW2rdGaeBycDx2mXcTIG7YfmS7N+mbLPKpu+BAwdi9erVKkjf70ONGzcO48ePv2s/AzUR5XQa2O5zN0yB+9TV6HT3O9rZqMFoWuBm/zYVykA9ZMgQLF++HFu3bkWFChXu+1jWqIkoL129HWfs307t4w6PSvu9EezfpkIVqKVoQ4cOxdKlS7F582ZUqVIl26/BwWRElJe/UWfCo0217Z1nbyAmITndY8z7t9tU80IxBzaTE6xnMNngwYOxcOFCVZt2cXFBWFiY2u/m5qbmVRMRWZJkOqvi7aK2vi0qpOvfltr2wUsRahWw4BsXsXD3Rbg7O6BfC3/0buYPt2LMS05Zo+sa9b3S/c2bNw+vvvpqll6DNWoispSouESVbEUC97pjVxEScceUVa3XI374X8sK8HIpaulikgVYTdN3bmCgJiI9SEpOwT9Hr2DW5rMICosyJVp5oWFZvN66EpfsLGQuZyM2cWkZIqJ8YGdro+Ztrx7eCj/0aaSmdSUkpWDB7oto8+VmDF90EEFh6TOmEem+j5qIyNpIl17bGt54vLqXahafufkstp66huWHQtXWtroXBrWphIblmdiJjBioiYgsFLCbViyltsCQSNUkvirwCjYEhatN5mYPblMZrat4cHnOQo6BmojIwmqVccPMXg1w7lo0Zm85hyUHL6va9p7ze1DT1xWDHquMjrV8YMtEKoUS+6iJiHSiomdxTHy+Dra+3UaNCC9mb4tjobcxeOEBPDF1Cxbvvaj6talwYaAmItKZ0m7F8OFTAfjv3ccxvG0VNef63PUYvPPXUbSetAnfbzuH2IQkSxeT8gmnZxER6VxMfBJ+23MRc7edw9XbxpSlJZzs8Wpzf7VxNa+Ch/OozTBQE5G1iE9KxpIDIZi95Swu3IhV+5wcbNG9UTm0q+GtpnwxRWnBwEBthoGaiKxNcooBq45ewbebz+LElbS51w62NqjnVwLNKpZCs0qlUN+vBBztGLj1iIHaDAM1EVkr+fnefOoa/j4cqhYEuRIZd9cSnI38S6J5JQ88UrEU6pR1g70thybpgdUsykFERPcm86tlRS7ZJGjLAiA7z93Af2dvqMB9PToeO87cUJtwdrBF4wruphp3TV83TvkqABioiYisJGj7ezirrWcTPxW4z16LNgVtCeARsYnYfPKa2oRLUTs0rVAKzSsZA3c1bxfYMHDrDgM1EZGVBu7KXi5qe6WZP1JSDGoxEAnYO89ex+5zNxEVl4R/T1xVm5BlOB+pqNW4PVDJ05lZ0XSAgZqIqBCQmnKAr6vaJJmKrOYlyVSMgfsG9l64iZsxCVh1NExtwtPFUaUybeBXUg1MkyxpHJyW/ziYjIiIkJicgiOXI/DfGWMz+b7gW3dlQZNR5TXLuJoCt1yWdivKWncOcDAZERFli4wGlxW7ZBvatgriEpNx8GIEDly8hYMXb+HAxQhV45Z9smm8XR3TBW7JW17UnrXu3MRATUREd5FgKwPMZBPS+HrxZmxq4DYG8BNXolSmtNWBYWoT9rZFEFDaFfXNgnfZksVY634IDNRERPRAEmjLl3JWW7f6xqZayTd+9HKkqm1rtW6ZEnb4cqTa5v9nfK5HcUdT0JZLmc/t5MDwk1U8UkRElCMSbLU1tbVa9+Vbd0y1bgneMmBNgvf641fVJmTutkwFq+DpjHIlnVSN27gZr7PpPD0GaiIiyrVadzl3J7V1qVdG7ZO+7sCQyHRN5tJcfvzKbbVlRkabmwfucmbB3LdE4QvkDNRERJRnJKg28ndXm1brllSnR0MicelmrKqBX75lvJTbMQnJuBYVrzbzQWvmvFwc1cmAeU1cC+alSxS1uilkDNRERJSvtW6pFcuWkQTxyDuJuHQzLXhf1oJ46mVsQjLCo+LVtj/4ViavD3gWd1S1cgnontqm9hVNu+3iqFKqFoRBbgzURESkCxI0ZW1t2WqXdcs0kN+KTVTB+17BPC4xxRTIjz3g/YrZ28LLVQvi5gE9/SaD4Sy5mAkDNRERFZhA7u7soLY6ZUtkGshvxCTgSkScGsCmmtBTL8Oj4kxN6rJJE/udxGS1kIlsDyLvKUG8RmkXTOtRH/mpQATqmTNnYvLkyQgLC0PdunUxY8YMNGnSxNLFIiIinQVyj+LGGvCDxMQnpQXz1IAefjt9cJdNHpOUYlDJXmQrap//NWvdB+rFixdj5MiR+O6779C0aVNMmzYNHTp0wMmTJ+Hl5WXp4hERUQHk7GinNpkXfj+ymEnEnURT4LaxQAu47lcQnzp1Kvr374++ffsiICBABWwnJyf8+OOPli4aEREVgsVM3J0dUM3HBS2reKB5JY/8LwN0LCEhAfv370e7du1M+2xsbNTtnTt3WrRsREREKOxN39evX0dycjK8vb3T7ZfbQUFBmT4nPj5ebZqoqKg8LycREVGhrFHnxIQJE+Dm5mbapLmciIiooNJ1oPbw8ICtrS2uXjXmh9XIbR8fn0yfM2bMGERGRpq248eP51NpiYiIClmgdnBwQMOGDbFhwwbTvpSUFHW7WbNmmT7H0dERrq6ups3FxSUfS0xERFSI+qiFTM3q06cPGjVqpOZOy/SsmJgYNQo8KySwiytXruRxSYmIiLJGi0lajCrQgfrFF1/EtWvXMHbsWJXwpF69elizZs1dA8zuRWs2Z4IUIiLSG4lRfn5+931MEYPkXLNiSUlJOHjwoArsMrXrYcgIchmcJv3ebFLPGh6z7OMxyz4es+zjMbPsMZOatATp+vXrw87OrnAH6tx0+/ZtNZJcBqlJ/zc9GI9Z9vGYZR+PWfbxmBWcY6brwWRERESFHQM1ERGRjjFQZ4NM/froo4/UJWUNj1n28ZhlH49Z9vGYFZxjxj5qIiIiHWONmoiISMcYqImIiHSMgZqIiEjHGKizYebMmfD390fRokXRtGlT7Nmzx9JF0vUqZo0bN1ZJAby8vNC1a1ecPHnS0sUqML744gsUKVIEI0aMsHRRdC0kJAQvv/wySpUqhWLFiqF27drYt2+fpYulW7Js8IcffogKFSqo41WpUiV88skn4FCl9LZu3Yqnn34avr6+6nu4bNmydPfL8ZJsmaVLl1bHsV27djh9+jTyCgN1Fi1evFjlHZcRfwcOHEDdunXRoUMHhIeHW7pourRlyxYMHjwYu3btwvr165GYmIj27durPO10f3v37sXs2bNRp04dSxdF127duoUWLVrA3t4eq1evVtmivvzyS5QsWdLSRdOtiRMnYtasWfjmm29w4sQJdXvSpEmYMWOGpYumKzExMeo3XipnmZFjNn36dHz33XfYvXs3nJ2dVTyIi4vLmwLJqG96sCZNmhgGDx5sup2cnGzw9fU1TJgwwaLlKijCw8PllN2wZcsWSxdF16KiogxVqlQxrF+/3vDoo48ahg8fbuki6dY777xjaNmypaWLUaB07tzZ0K9fv3T7nn32WUOvXr0sVia9A2BYunSp6XZKSorBx8fHMHnyZNO+iIgIg6Ojo+G3337LkzKwRp0FCQkJ2L9/v2re0EjecLm9c+dOi5atoJCUe8Ld3d3SRdE1aYXo3Llzur81ytyKFSvUqnovvPCC6l6RnMlz5861dLF0rXnz5mqZ4FOnTqnbhw8fxvbt29GpUydLF63AOH/+vFogyvw7KmlFpTs0r+KB7lfP0oPr16+rvp2MK3bJ7aCgIIuVq6CQ5PPS1yrNlLVq1bJ0cXRr0aJFqltFmr7pwc6dO6eacaVL6r333lPHbdiwYWode1kal+727rvvqnzV1atXh62trfpd++yzz9CrVy9LF63ACAsLU5eZxQPtvtzGQE35UksMDAxUZ+6UuUuXLmH48OGqP18GK1LWTgClRv3555+r21Kjlr8z6TdkoM7c77//jgULFmDhwoWoWbMmDh06pE6iZdAUj5l+sek7Czw8PNTZp7a2tUZu+/j4WKxcBcGQIUOwcuVKbNq0CWXLlrV0cXRLulZkYGKDBg3UkneyyYA8GbAi16XmQ+nJiFtZctBcjRo1cPHiRYuVSe9Gjx6tatU9evRQI+R79+6NN998U83SoKzRfvPzMx4wUGeBNKU1bNhQ9e2Yn83L7WbNmlm0bHolYzAkSC9duhQbN25U00Ho3tq2bYujR4+qGo62SW1RmiTlupwoUnrSlZJxyp/0vZYvX95iZdK72NhYNb7GnPxtye8ZZY38lklANo8H0p0go7/zKh6w6TuLpB9Mmobkx7NJkyaYNm2aGsLft29fSxdNt83d0ry2fPlyNZda67uRQRcy75DSk2OUsf9epnzI/GD262dOaoIyOEqavrt3767yGsyZM0dtlDmZGyx90n5+fqrp++DBg5g6dSr69etn6aLpSnR0NM6cOZNuAJmcMMtgWDl20l3w6aefokqVKipwy9x06T6QfBF5Ik/GklupGTNmGPz8/AwODg5qutauXbssXSTdkj+tzLZ58+ZZumgFBqdnPdjff/9tqFWrlpoaU716dcOcOXMsXSRdu337tvqbkt+xokWLGipWrGh4//33DfHx8ZYumq5s2rQp09+vPn36mKZoffjhhwZvb2/1t9e2bVvDyZMn86w8XD2LiIhIx9hHTUREpGMM1ERERDrGQE1ERKRjDNREREQ6xkBNRESkYwzUREREOsZATUREpGMM1ERERDrGQE1Eua5IkSJYtmyZpYtBZBUYqImszKuvvqoCZcatY8eOli4aEeUAF+UgskISlOfNm5dun6Ojo8XKQ0Q5xxo1kRWSoCxL8ZlvJUuWVPdJ7XrWrFno1KmTWsmsYsWK+PPPP9M9X5bcfPzxx9X9soLXgAED1IpC5n788Ue1ApO8l6wNLcuamrt+/Tq6desGJycntcrQihUrTPfdunVLLeHp6emp3kPuz3hiQURGDNREhZAsy/fcc8/h8OHDKmD26NEDJ06cUPfJ8q0dOnRQgX3v3r34448/8O+//6YLxBLoZSlTCeAS1CUIV65cOd17jB8/Xi0/eeTIETz55JPqfW7evGl6/+PHj2P16tXqfeX1PDw88vkoEBUQebYuFxFZhCzFZ2tra3B2dk63ffbZZ+p++dq/8cYb6Z7TtGlTw8CBA9V1WSqyZMmShujoaNP9//zzj8HGxsYQFhambvv6+qrlEe9F3uODDz4w3ZbXkn2rV69Wt59++mlD3759c/mTE1kn9lETWaE2bdqoWqo5WfRe06xZs3T3ye1Dhw6p61LDrVu3LpydnU33t2jRAikpKTh58qRqOg8NDUXbtm3vW4Y6deqYrstrubq6Ijw8XN0eOHCgqtEfOHAA7du3R9euXdG8efOH/NRE1omBmsgKSWDM2BSdW6RPOSvs7e3T3ZYAL8FeSP94cHAwVq1ahfXr16ugL03pU6ZMyZMyExVk7KMmKoR27dp11+0aNWqo63IpfdfSV63ZsWMHbGxsUK1aNbi4uMDf3x8bNmx4qDLIQLI+ffrg119/xbRp0zBnzpyHej0ia8UaNZEVio+PR1hYWLp9dnZ2pgFbMkCsUaNGaNmyJRYsWIA9e/bghx9+UPfJoK+PPvpIBdFx48bh2rVrGDp0KHr37g1vb2/1GNn/xhtvwMvLS9WOo6KiVDCXx2XF2LFj0bBhQzVqXMq6cuVK04kCEaXHQE1khdasWaOmTJmT2nBQUJBpRPaiRYswaNAg9bjffvsNAQEB6j6ZTrV27VoMHz4cjRs3VrelP3nq1Kmm15IgHhcXh6+++gqjRo1SJwDPP/98lsvn4OCAMWPG4MKFC6opvVWrVqo8RHS3IjKiLJP9RGSlpK946dKlagAXEekf+6iJiIh0jIGaiIhIx9hHTVTIsLeLqGBhjZqIiEjHGKiJiIh0jIGaiIhIxxioiYiIdIyBmoiISMcYqImIiHSMgZqIiEjHGKiJiIh0jIGaiIgI+vV/xCAdgmOpt7wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epoch_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
