{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpt import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_block): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx is a (batch_size, n_tokens) array of indices in the current context\n",
    "def generate_text_sample(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        \"\"\"\n",
    "        crops current context if it exceeds the supported context size\n",
    "        eg: if LLM supports only 5 tokens and the context size is 10\n",
    "        only 5 tokens are used as context\n",
    "        \"\"\"\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        \"\"\"\n",
    "        Focuses only on the last time step so that (batch_size, n_tokens, vocab_size)\n",
    "        becomes (batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "        logits = logits[:,-1,:]\n",
    "        # probas has shape (batch_size, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        # idx_next has shape (batch_size, 1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        \"\"\"\n",
    "        Append sampled index tot he running sequence\n",
    "        where idx has shape (batch, n_tokens+1)\n",
    "        \"\"\"\n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexAngel214nesiumfigured\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_sample(\n",
    "    model = model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Output text:\\n {token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text evaluation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833,3626,6100],       #every effor moves\n",
    "                       [40,1107,588]])          #I really like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626,6100,345],        #effort moves you\n",
    "                        [1107,588,11311]])      #really like chocolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Ids: tensor([[[16657],\n",
      "         [16031],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"Token Ids: {token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Output batch 1:  Armed savesNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Output batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.9576e-05, 1.5754e-05, 1.1587e-05,  ..., 2.1908e-05,\n",
       "          7.0255e-06, 1.8478e-05],\n",
       "         [9.4945e-06, 1.0247e-05, 7.7444e-06,  ..., 2.8397e-05,\n",
       "          6.1837e-06, 1.2869e-05],\n",
       "         [2.8746e-05, 8.5582e-06, 1.5153e-05,  ..., 3.7397e-05,\n",
       "          1.3669e-05, 1.2614e-05]],\n",
       "\n",
       "        [[1.2261e-05, 2.0023e-05, 1.3299e-05,  ..., 1.0177e-05,\n",
       "          3.5075e-05, 1.3706e-05],\n",
       "         [7.4842e-06, 1.7175e-05, 1.0332e-05,  ..., 2.1160e-05,\n",
       "          1.1552e-05, 1.4645e-05],\n",
       "         [2.8896e-05, 3.3004e-05, 4.2034e-05,  ..., 6.6369e-06,\n",
       "          5.7847e-05, 1.3099e-05]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.1165e-05, 3.1117e-05, 1.1661e-05])\n"
     ]
    }
   ],
   "source": [
    "text_ids = 0\n",
    "target_probas_1 = probas[text_ids, [0,1,2], targets[text_ids]]\n",
    "print(\"Text 1:\", target_probas_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 2: tensor([1.0360e-05, 5.3230e-05, 4.7808e-06])\n"
     ]
    }
   ],
   "source": [
    "text_ids = 1\n",
    "target_probas_2 = probas[text_ids, [0,1,2], targets[text_ids]]\n",
    "print(\"Text 2:\",target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5505, -10.3778, -11.3593, -11.4776,  -9.8409, -12.2509])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1,target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.8095)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8095)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this can be done via a single function in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape:torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logits shape:{logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine batch size and number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flatteneed targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(f\"Flattened logits: {logits_flat.shape}\")\n",
    "print(f\"Flatteneed targets: {targets_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8095)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49487.9023)\n"
     ]
    }
   ],
   "source": [
    "preplexity = torch.exp(loss)\n",
    "print(preplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the verdict dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Total characters: {total_characters}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "test_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "test_loader = create_dataloader_v1(\n",
    "    test_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify created data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loaders:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Validation Loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train loaders:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(f\"Validation Loader\")\n",
    "for x, y in test_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross entropy loss for batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i,(input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss/num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.986397849188911\n",
      "val_loss: 10.980345726013184\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cude\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device\n",
    "        )\n",
    "    val_loss = calc_loss_loader(\n",
    "        test_loader, model, device\n",
    "    )\n",
    "print(f\"Training loss: {train_loss}\")\n",
    "print(f\"val_loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                      )\n",
    "                \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample( model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_sample(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n',' '))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (step 000000): Train loss 9.753, Val loss 9.884\n",
      "Ep 1 (step 000005): Train loss 8.118, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (step 000010): Train loss 6.675, Val loss 7.051\n",
      "Ep 2 (step 000015): Train loss 5.997, Val loss 6.629\n",
      "Every effort moves you, and,, and,,,,,,, and,,,,,,,,,,,,,,,, and,,,, and,,,,,,,, and,,,,,,\n",
      "Ep 3 (step 000020): Train loss 5.746, Val loss 6.500\n",
      "Ep 3 (step 000025): Train loss 5.546, Val loss 6.433\n",
      "Every effort moves you, and, and I had to the to the, and I had to the of the--I, and, and I had to to the the of the the of the, and I had to the of the of the of the to the of\n",
      "Ep 4 (step 000030): Train loss 4.792, Val loss 6.393\n",
      "Ep 4 (step 000035): Train loss 4.382, Val loss 6.276\n",
      "Every effort moves you know the picture.    \"--and it a of the of the of the picture to me.     \"I it--and it to the picture to the picture to the of the picture of the of the of\n",
      "Ep 5 (step 000040): Train loss 3.822, Val loss 6.208\n",
      "Every effort moves you know it was not to have to have to see the fact of the last--his, and--his--and here are the sketch of the fact of his pictures--as, and in the sketch of the donkey.      \n",
      "Ep 6 (step 000045): Train loss 2.929, Val loss 6.175\n",
      "Ep 6 (step 000050): Train loss 2.457, Val loss 6.185\n",
      "Every effort moves you know,\" was not that my dear, and he had been the his last word. Gisburn's an!                           \n",
      "Ep 7 (step 000055): Train loss 2.111, Val loss 6.189\n",
      "Ep 7 (step 000060): Train loss 1.769, Val loss 6.271\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.        \"Oh, in the moment--as Jack himself, one might put it, had been the--because he's. The\n",
      "Ep 8 (step 000065): Train loss 1.161, Val loss 6.298\n",
      "Ep 8 (step 000070): Train loss 0.834, Val loss 6.317\n",
      "Every effort moves you?\"     I glanced after him, and uncertain.           He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 9 (step 000075): Train loss 0.550, Val loss 6.332\n",
      "Ep 9 (step 000080): Train loss 0.389, Val loss 6.454\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, my eye fell on a small picture\n",
      "Ep 10 (step 000085): Train loss 0.268, Val loss 6.491\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, moved aside a _jardiniere_ full of\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, test_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens sees\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epoch_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_sample(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Output text: {token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\":0,\"every\":1,\"effort\":2,\"forward\":3,\"inches\":4,\"moves\":5,\"pizza\":6,\"toward\":7,\"you\":8\n",
    "}\n",
    "inverse_vocab = {v:k for k,v in vocab.items()}\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51,0.89,-1.90,6.75,1.63,-1.62,-1.89,6.28,1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits,dim=-1)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use multinomial instead of argmax for temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat for 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "              for _ in range(1000)]\n",
    "    sample_ids = torch.bincount(torch.tensor(sample))\n",
    "    print(sample_ids)\n",
    "    for i, freq in enumerate(sample_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 73,   0,   0, 582,   2,   0,   0, 343])\n",
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits/temperature\n",
    "    return torch.softmax(scaled_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1,0.1,5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x+i*bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature={T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top pos: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k=3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(f\"Top Logits: {top_logits}\")\n",
    "print(f\"Top pos: {top_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits<top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=-1)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(\n",
    "                logits<min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature>0.0:\n",
    "            logits=logits/temperature\n",
    "            probas=torch.softmax(logits, dim=-1)\n",
    "            idx_next=torch.multinomial(probas,num_samples=1)\n",
    "        else:\n",
    "            idx_next=torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        if idx_next==eos_id:\n",
    "            break\n",
    "        idx=torch.cat((idx,idx_next),dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know where to go a little wild--I he was a good.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(f\"Output text:\\n {token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_block): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save both model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\":model.state_dict(),\n",
    "    \"optimizer_state_dict\":optimizer.state_dict()\n",
    "},\n",
    "\"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_block): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_ptoj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model=GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
