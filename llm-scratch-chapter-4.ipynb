{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Implementing a GPT model from scratch to generate text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding Dimension\n",
    "    \"n_heads\": 12,          # Number of Attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout Rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value Bias\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place holder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg)\n",
    "             for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before stach: [tensor([6109, 3626, 6100,  345]), tensor([6109, 1110, 6622,  257])]\n",
      "after stack: tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "after batch: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "print(f\"before stach: {batch}\")\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(f\"after stack: {batch}\")\n",
    "print(f\"after batch: {batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(f\"Output shape: {logits.shape}\")\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Normalization example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2595e-01, 3.4695e-01, 0.0000e+00, 2.2160e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.1328e-01, 2.3942e-01, 0.0000e+00, 5.1984e-01, 3.2975e-01, 0.0000e+00]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examining the mean and varience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([[1.3242e-01],\n",
      "        [2.1705e-01]], grad_fn=<MeanBackward1>)\n",
      "varience: tensor([[2.3066e-02],\n",
      "        [3.9823e-02]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"varience: {var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying layer normalization manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized layer: tensor([[6.1585e-01, 1.4126e+00, -8.7188e-01, 5.8723e-01, -8.7188e-01, -8.7188e-01],\n",
      "        [-1.8865e-02, 1.1211e-01, -1.0876e+00, 1.5173e+00, 5.6474e-01, -1.0876e+00]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean)/torch.sqrt(var)\n",
    "print(f\"normalized layer: {out_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "print(f\"mean: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: tensor([[1.0000e+00],\n",
      "        [1.0000e+00]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(f\"var: {var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulating Layer Normalization to PyTorch module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x-mean)/torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "var: tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"var: {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2/torch.pi)) * \n",
    "            (x + 0.044715 + torch.pow(x,3))\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot GELU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXBNJREFUeJzt3QdY1dUbB/AvG0HBDSq4FcUtqKmVWm4bNsys1IaVpZVZVprZ36ysbFhqqWlZlrlKrRw5cmRqKu6FW0RRxAHIHvf/vIcuMS7K/o37/TzPT+693HHOvfI794z3PQ4Wi8UCIiIiIiKiInAsyoOJiIiIiIgEOxZERERERFRk7FgQEREREVGRsWNBRERERERFxo4FEREREREVGTsWRERERERUZOxYEBERERFRkbFjQURERERERcaOBRERERERFRk7FkQ2/O9//4ODg4Mmrz1nzhz12qdPny71105NTcVrr70Gf39/ODo6om/fvtAjLd8jIrJvnTt3VocWHn/8cdSuXVuT17548SIefPBBVKpUSZ1/J0+eDD3S8j0idizs0qlTpzB8+HA0bNgQHh4e6ggMDMSwYcOwb98+m1+w8zouXLig7idf8OT6xx9/nOfryh/6XXfdZfN3O3fuVI+XL4ylJT4+XtVvw4YN0ML777+PpUuXQk+++eYbTJo0STUe3333HV5++WVNy6PH94jIrKwdduvh7OyMGjVqqC9q586dy3V/+XKdV9vQqFGjXM8r53lbbtZ+yO2lPZBw6NAh1T5oMXhx/vx59dp79uyBnkh78Mcff2D06NGYO3cuevbsqVlZ9PoeEeCsdQGodP3+++/o37+/ajAeffRRtGjRQo1MHzlyBL/88gu++uor1fGoVatWtsfJ7WXLls31fOXLl4dRScdi/Pjx6nLO0aexY8fijTfeKPEvzfIFPueswMCBA/Hwww/Dzc0Npe3PP/9UXyQ+++wz6IEe3yMis3vnnXdQp04dJCYmYtu2bapjsHnzZhw4cADu7u7Z7uvn54eJEyfmeg5vb28YmXQspH2QtiHn6Pfq1atL/EuzvLa8bsuWLbP97uuvv0Z6ejq0IO3Dvffei1dffRVa0+t7ROxY2JUTJ06oL2PSaVi3bh2qVauW7fcffvghvvzyS9XRyEm+3FWuXBn2QjpecmjByclJHVqIjIw0RGdRy/eIyOx69eqF4OBgdXnIkCHq3C/tw6+//oqHHnooVwfisccegz1xdXXV7LVdXFw0e22jtA9avkfEpVB25aOPPkJcXBy+/fbbXJ0KIV+kX3zxRbW+Xq+uXLmiRkuaNWumZlC8vLxUI7h3795c95XRNpkqlSVfMsomdb7//vtVB0umt6tUqaLuJ6Me1ul7ub+tGIumTZuiS5cuuV5DRkVkhF86Xlmn7Tt06KDWoZYpUwZBQUFYvHhxtsfJc8tnIcuNrK8tyw1uFD8gnb4mTZqoUfrq1aurpWvXrl3Ldh8ZXZOyymiblFeWuUn55LO/EetShPXr1+PgwYOZZZJlYnJYL9t6TNbla1IH+Vxk2YTMMshleZ/lM0tLS8v13n3++efqs5TPR+4nU+vW5RJ6e4+I7NVtt92mfsq5U89kKa+cI+rWravOKb6+vnjyySdx+fLlXPeVc9RTTz2lzhNyvpAZmueeew7Jycnq/NKvXz91PzlHZD0f5oyxkLgDaTuts99ZhYaGqsdNnTo13+2XvEabNm3U5SeeeCLzta3nWVvxA3KefOWVV1TbLXUJCAhQ7ZDFYsl2P3keWQYty0vlHCj3lfPlqlWrbvi+Ws+38nzTpk3LLNON4hFtnaOty6Fl9qtt27bqM5LP6vvvv8/1eDlvy9IreYyUU2bGBg0ahKioKF2+R/QfzljY2TKo+vXro127dgV+rJwQc5KTaWmPXpw8eVL9wctJXxoCOanPmDEDnTp1Ul8UpZEQ8iVWTmAyMyOzNC+99BJiY2OxZs0aNZ3ftWtXtbxLGpL77rtPdThE8+bNbb6uLB+TE6jElEhjZSUnSJmSldewki/L99xzj1pqJo3U/PnzVXnl/e/Tp4+6j6xPlZFAObk+88wz6rZ69erlWW95bWm4pNxSZmmwpPw7duzA33//nW2E5urVq+oLutRJRhelU/P666+rxkwaMVvkS72U6b333sP169czlzY0btwYhw8fLtBnJO99jx491P8zOXGvXbsWn3zyiaqflN1KGnVpCKRM8l5I4Phff/2lll7IaKne3iMie2X9clihQgWbf+/yZS8nGVTx9PREaZLzu7QR8mVTztMySDJz5kz1U84r1i/Acs6W84p8eZVzi8SDSEdDzgOyRPb2229Xg2xffPEFxowZo86DwvozKx8fH9X+LFy4EG+//Xa23y1YsEDNrFo7Kflpv+Q1ZCnauHHjVNmsnToZrLJFvhhLeyODQnJOlWVBEgcxatQoVaecy1qlzZJlz88//zzKlSun6vjAAw8gLCxMDYbZIu+HnI9lCWq3bt3UF/zCOn78uBqIk7IOHjxYxfVJR0AG4OQLvJA2SOotbY90DFu3bq3+j8mMWXh4uC7fI8rCQnYhOjpauuWWvn375vrd1atXLZcuXco84uPjM3/39ttvq8fZOgICAjLvd+rUKXXbpEmT8ixDrVq1LH369LH5ux07dqjHf/vttzesR2JioiUtLS3bbfLabm5ulnfeeSfztm+++UY936effprrOdLT09VPqavcR+qYk7XeVqGhoer6lClTst3v+eeft5QtWzbbe5b1skhOTrY0bdrUcscdd2S73dPT0zJ48OBcry3vgbyW1EtERkZaXF1dLd27d89W96lTp6r7SV2tOnXqpG77/vvvM29LSkqy+Pr6Wh544AHLzcjjmzRpku229evXq+eUn1lZP/Osn5nUR27L+lmIVq1aWYKCgjKv//nnn+p+L774Yp6fj17fIyKzsv5drV27Vp0fz549a1m8eLGlSpUq6hwr17Oy/i3ZOp599tlczyvneVtu1n7I7Vn/3vOS89wrfvrpJ/XYTZs2Zd42aNAgi6Ojo83yWM8/ixYtsnnes9ZbDqsZM2ao++7fvz/b/QIDA7Od9/Pbft2oPZTzobSlVkuXLlX3fffdd7Pd78EHH7Q4ODhYjh8/nnmb3E/Ok1lv27t3r822zRa537Bhw27YVuZ1jhZS7pyfhZy7pf6vvPJK5m3jxo1T9/vll1/y/Hz0+h6RxcKlUHYiJiZG/bQVgC1TujJibT1kqjOnn3/+WY0GZT1kSVVpk2lJawyIjJTJFLfUSaY1d+3ala28si74hRdeyPUchUkjK8upZJRDRqCs5PVlhOvuu+9Wo3NWWS/LyHh0dLQaUclavoKQEX+Z+RgxYkS2+Jenn35aTaUvX7482/3l/ci65lnWA8vonIyWlZahQ4dmuy71z/r68vnI55BzhK+wn48R3yMivZJZP2kLZNmIjC7LzIOMFstylJxkyUnOtkEO+VssbVnPvbIUVka5b7nlFnXdev6VJZgyayDnbWscSVHPPzLzKTP4WdsHmRmXWQiZ7S5o+1UQK1asULMiMsOSlSz7ke/JK1euzPXZZp35lVl6OUeW1rlPMlBaZxiE/D+T+udsHySxjKwmKI7Px2jvkdFxKZSdkOk86xRjTjIVK8uEZFo2ryA8mQotjeDtm500rOvyZS29ZK/Kum4/6xSlrAWWk1VxBmBLAyHT4jJ1KmvyZZ2nBLNlbTiELHl69913VRq8pKSkfNctL2fOnFE/pT5ZyZdhWZ9q/b2VNP45X0uWMORMJVxSrPESOV9fOllZPx+Z9q9YsWKxvKbR3iMiPZPBJRlMkUERWaqyadOmPDOwSadDvoiVhpudQ2XJriyHlOWncm7OSuoiLl26pAbaZP18cZG28c4771TLoSZMmKBuk06GtD/WZbYFab8KQs5tci61tvFW1mVbOc99NWvWzPUcOc/PJSk/ry/tgyw9Ki5Ge4+MjjMWdkIyd0jwsoyi5CRr4aVh6NixY4l/4UxISLD5O1nXar3PzdKPjhw5UnV0fvjhB7VOUkbHZG1mSaeXkw6EjG4sWrRIXZdGRN7XrLm8JUZA1nJKPaTxkJESKd8jjzySK0ispOSVLamwr59XY54zGPtmr68nxf0eEZmJzN5JmyBf7mSmQr6EyznM1sBUcbCe94vaPki8lKQalRlTWSMvaWGtQbcl3T5InN3Ro0cz91WQ9kE6G1kH5LRsv/TePujp3GuEMuoZOxZ2RAKHJXBq+/btmry+pLmVE68tEmhrvc+NyNIjydIxe/ZsdSLv3r27agBzZv6RaUx5zpSUlDyfq6AzCBJsJw2ujERJoLE0XJL5KOtInkzhSuMnDYYEnUkgcF6jefl9fet7Yn2PrGTpj609R4qbNWAz53ucc5SnIOTzkQBKW0kBjPgeEZmVfMmSZA7y92rNblTcZIZTsrPl/Pu1ktvl9zeaNZfRZEnWIfsPyayFLKORQGOZscz5WrKsxdYgW1HaB2kLZIZU2gfpXEhblzWpR0Har4K8tpzb5LORVQdZyd5U1t8bsX0ozs9H6/fI3rBjYUdee+01dXKWL7yy7Km0e+O9e/dWGR1y7qQsy4VmzZqFqlWrquwPN2vkcpZTZhBy7gorI22yvtZWQ2h9vLwXtk6IN5u1kOwisjxAnj/nMigpn5zwso7WSEYVW7tHyxKC/Ly2NDzSYElmiqx1l8ZJpvetmaZKipx0pV6yHCIrmZEpLPl8pC62UjRmraNR3iMiM5M4PBlUmTx5sopdKG5yfpEv2b/99pvKvJOVXJfb5fc3mg21/i5n+yBlzkpiHKQTIM9paydw6+OtGa3y2z5IhkTJhiczFbIUS85HOTf2zG/7VZDXlnZV2pucbZ1kOpK2qKSz3FljEbK2D9Y04UVpHyQF75IlS4rl89H6PbI3jLGwIw0aNMC8efMwYMAAtRbduvO2/KHKqK78Tk66tgL0ZKTFVuC3jAhJuj0rGTGy1fDICVbSwskXckm1J52bVq1aqeA1GeGR0QnJZX2zjYckhaykmZN0gpJabv/+/fjxxx9zjUpJOjx5Ppl2lhkaCRaTk50E+UoKOdk9VAL9JJBMXl/WE8t6f5nyv9HaW5lqlzzkcsj9c85GyBfYTz/9VC2PkqUDss5X1itLmt+c6/clvZ6UR+4v6z9lRsRWKmAZYRs9erT6Ei7PK0utZARPvthLLu+S3pxKlnvJZzZlyhR1EpaGROJIcq5hLggZtZPUhdIROHbsmKqXLAWQpWTyO8kjbqT3iMjsJDWnnAckRXTW5AzScZdlPbbk/LuT87+t/QAkHbgsE5JAaxlckrZCgsJlUEbSxcp5R35/IzILIUuMZD8amamWODhZCiVtW07yXPI7SfMqryVr7SMiItSXfEk1Kp0ESdYhHQHZGFDqKDPTd9xxhxoAy4sMNEmd5bwjnYyc6djz237JOVYeO336dBUXIF+i5bwn57+cJAhdzplvvvmmer+kTZe6LVu2TAXQ3yhFd3GQDp/EJEgaV/k/Iu+ZfM5yTs7ZScwveR75zmH9riDtgMxuy7I8eU+kjkZ6j+yO1mmpqPRJGrXnnnvOUr9+fYu7u7ulTJkylkaNGlmGDh1q2bNnT7b73ijdbNZUfNZ0gXkdc+fOzUxt+/LLL1vq1KljcXFxsXh5eVm6dOliWblyZb7KLun6JC1dtWrVVLk7duxo2bp1a670f9bUg2+++Wbma0k6UUkvd+LEicz7bNmyRaVBlfRyWVPP5pVCT8hryu+GDBli8/ezZ8+2NGjQQKXQk/dV0uHZer4jR45Ybr/9dlUP+Z01raqtNH3W1KnyfFIXHx8f9RnK+3mzdLG20u/lJa/HS+pJScXq4eFhqVChgkoleeDAAZvpZiVFbE626p+amqrSSEqd5P2XlJa9evWyhISE6Po9IjKrG6WFlTSp9erVU4f87d4s3WzWv3fr8+Z1WNPYHj582NK/f39L1apVLc7Ozurnww8/rG7Pj/DwcMt9991nKV++vMXb29vSr18/y/nz522mFT9z5oxKO2tNpVu3bl2VSlVST1t9/fXX6nYnJ6ds7Z2t9kbExMRknqt++OGHIrVfy5YtU+lq5X3Iep61dZ6KjY1V7Wr16tXVuU/aHzm3Zk3dnVe6WCHPZyutd055PV7O2e3atVPn8Zo1a6o073mlm7WVct5W/S9fvmwZPny4pUaNGup5/fz8VBmjoqJ0/R6RxeIg/2jduSEiIiIiImNjjAURERERERUZOxZERERERFRk7FgQEREREVGRsWNBRERERERFxo4FEREREREVGTsWRERERERUZHa3QZ5swiVbu8uGKgXZEp6IyMwk83hsbKzaiFA2yrRXbCOIiArfPthdx0IaDH9/f62LQUSkS2fPnoWfnx/sFdsIIqLCtw9217GQUSjrm+Pl5VWgx6akpKht4GULexcXFxiVGerBOuiHGephhjoUtR4xMTHqC7X1HGmv7L2NYB30wwz1MEMdzFKPlFJqH+yuY2Gd2pYGozCNhoeHh3qcUf9jmaUerIN+mKEeZqhDcdXD3pf/2HsbwTrohxnqYYY6mKUeKaXUPtjvQloiIiIiIio27FgQEREREZGxOxZfffUVmjdvnjnl3L59e6xcufKGj1m0aBEaNWoEd3d3NGvWDCtWrCi18hIRUelg+0BEZDyadiwksvyDDz5ASEgIdu7ciTvuuAP33nsvDh48aPP+W7ZswYABA/DUU09h9+7d6Nu3rzoOHDhQ6mUnIqKSw/aBiMh4NO1Y3H333ejduzcaNGiAhg0b4r333kPZsmWxbds2m/f//PPP0bNnT4waNQqNGzfGhAkT0Lp1a0ydOrXUy05ERCWH7QMRkfHoJsYiLS0N8+fPR1xcnJrytmXr1q3o2rVrttt69Oihbicismcpael4+7dDuJwI02H7QERUNH8di8Kf5x3UZnclSfN0s/v371cNRWJiohqNWrJkCQIDA23e98KFC/Dx8cl2m1yX2/OSlJSkjqy5eK1pt+QoCOv9C/o4vTFDPVgH/TBDPYxeB2ko3v7tMH7aEY5Kbk64v3cSPAv4HHqse0m3D4JtRHasg36YoR5mqIMZ6nHmSjxGLNyHmEQnBO8Iw8NtaxXo8QWpt+Ydi4CAAOzZswfR0dFYvHgxBg8ejI0bN+bZeBTUxIkTMX78+Fy3yyYhks+3MNasWQMzMEM9WAf9MEM9jFqHTREO+Pm0ExxgwX2107Hxz3UFfo74+HjoTUm3D4JthG2sg36YoR5mqINR65GUBnx2wAkxiQ6oVdYCj8iDWLHCdqxacbQPmncsXF1dUb9+fXU5KCgIO3bsUGtlZ8yYkeu+vr6+uHjxYrbb5LrcnpfRo0dj5MiRuXYPlJ0HC7P5kfyn6tatm2E3SDFLPVgH/TBDPYxch7+OR2HJtl3q8sg766Fm/NFC1cM6Uq8nJd0+CLYR2bEO+mGGepihDkauh8ViUTMVEfEXUcnTFU82jEevHiXbPmjescgpPT0927R0VjIlvm7dOowYMSLzNvmg81pzK9zc3NSRk7yphf3PUZTH6okZ6sE66IcZ6mG0OhyPjMVLC/Yh3QI80NoPz3aqh5UrjxaqHkaod3G3D4JthG2sg36YoR5mqIMR6zF94wmsOHARzo4OmDqgBSIPbi3x9kHTjoWMFPXq1Qs1a9ZEbGws5s2bhw0bNuCPP/5Qvx80aBBq1KihpqrFSy+9hE6dOuGTTz5Bnz59VDCfpCGcOXOmltUgIip1V+OS8dR3OxGbmIrgWhXw/v1N4WBJh1mwfSAiKrxNRy/ho1VH1OW372mi2okCroAqFE07FpGRkapxiIiIgLe3t9oMSRoNmWoSYWFhcHT8L3FVhw4dVOMyduxYjBkzRqUhXLp0KZo2baphLYiISldyajqG/hCCM5fj4VehDGYMDIKbsxNSUszTsWD7QERUOGGX4/HCT7vVbHa/ID881q4mUlNTURo07VjMnj37hr+X0amc+vXrpw4iInukMkD9egD/nLqCsm7OmD24DSqVzb2Ux+jYPhARFVx8ciqembsT0QkpaOFfHhP6NoWDgwPsbh8LIiK6uW/+Po2ftp+FtBNfDGiJAN9yWheJiIh0MvD0+s/7ceRCLCqXdcX0x1rD3cWpVMvAjgURkUGsD43Ee8sPqctjejXGHY2y79tARET2a9Zfp/Db3vMqWPvLR4NQzbtMqZeBHQsiIgM4djEWL87LWDPbP9gfQ26ro3WRiIhIJzYfi8LElYfV5bfuCkTbOhU1KQc7FkREOnclLhlPfrcDsUmpqrEo7TWzRESkX2evxGP4T7vUwNODQX4Y1L5gO2sXJ3YsiIj0ngFqbgjOXklAzYoemP5YEFydeeomIiIgITkNz84NwbX4FDT388a7Gg88sXUiItJxIN6bS/Zj++krKKcyQAWjoqer1sUiIiKdtBFv/LIPhyJi1M7aMvBU2sHaObFjQUSk40C8RSHhcHQApjzSCg18mAGKiIgyzN58Csv2nIeTowOmPdoa1cuXfrB2TuxYEBHp0LrDF/F+lkC8zgFVtS4SERHpxJbjEqydsbP22D6NcUvdStADdiyIiHTmyIUYvPjTblgswIC2NfF4h9paF4mIiHQi/KoEa+9GWroF97euoas2gh0LIiIdibqehKfm7ERccho61KuEd+5twgxQRESkJKZkBGtLtsCmNbzw/n3NdNVGsGNBRKQTSalpKgPUuWsJqF3JA18+2houTjxNExERVLD2mF/24+D5GJXIQw/B2jmxxSIi0kmDMfqX/dh55irKuTtj9uNtUN6DGaCIiCjDnC2n8cvucypYe+ojreBXwQN6w44FEZEOTN94Er/symgwZKaiXpWyWheJiIh0YtvJy3h3eUZCjzG9G6NDvcrQI3YsiIg09sfBC/joj4zsHv+7OxC3NaiidZGIiEgnzl1LwLAfd6lg7b4tq+PJjvoJ1s6JHQsiIg0dOh+DlxfsURmgBrWvhYHt9dtgEBFR6QdrP/dDCC7HJSOwmhcm3t9cV8HaObFjQUSkkcjYRAz5bgfik9Nwa/3KGHdXoNZFIiIiHcXevbnkAPaFR6OChwtmDAxCGVd9BWvnxI4FEZFGo1DPfB+C89GJqFvFE9MeaQ1nZoAiIqJ/fb/1DH7eFQ5HB2DqI63hX1F/wdo5sRUjItJgFOr1n/dhz9lr8C7jgtmD28Dbw0XrYhERkU78c/IyJvx+SF0e3asxOtbXZ7B2TuxYEBGVsmnrj2PZnvNwdnTAV4+1Rp3KnloXiYiIdCIiOgHD5u1CaroF97SojiG31YFRaNqxmDhxItq0aYNy5cqhatWq6Nu3L0JDQ2/4mDlz5qiglayHu7t7qZWZiKgoVu6PwMerj6rL4+9totuUgUREpM0y2aFzQxB1PRmNq3nhwwf0Haytq47Fxo0bMWzYMGzbtg1r1qxBSkoKunfvjri4uBs+zsvLCxEREZnHmTNnSq3MRESFdeBcNF5euEddfrxDbTzarpbWRdItDjwRkT0uk31r6QHsDY9Wy2RnPKb/YO2cnLV88VWrVuVqFKQBCQkJwe23357n46Sx8PX1LYUSEhEVj4sxkgFqJxJT0nF7wyoY26ex1kXSNevAk3QuUlNTMWbMGDXwdOjQIXh6et5w4ClrB8RII31EZN9++CcMi0KswdqtULOS/oO1ddWxyCk6Olr9rFix4g3vd/36ddSqVQvp6elo3bo13n//fTRp0sTmfZOSktRhFRMTo37K7IgcBWG9f0EfpzdmqAfroB9mqEdJ1yEhOU2llb0Qk4i6lT0xuV9TWNLTkJKeppt66O3z48ATEdmTHaevYPyvB9Xl13s2MuxGqbrpWEgnYcSIEejYsSOaNm2a5/0CAgLwzTffoHnz5qoj8vHHH6NDhw44ePAg/Pz8bE6njx8/Ptftq1evhodH4XqCsmzLDMxQD9ZBP8xQj5Kog2x8990xR+y/7AgPZwse9Y/GX3+u0V094uPjoWclMfBERKSXGe3nf8wI1u7TvBqeub0ujEo3HQuZ8j5w4AA2b958w/u1b99eHVbSqWjcuDFmzJiBCRMm5Lr/6NGjMXLkyGwzFv7+/mpKXabMCzqiJw12t27d4OJi3NSQZqgH66AfZqhHSdZhyp8nsPvyCZUBauagYLSrc+MvxlrVwzqbq0clNfAkOKudHeugH2aohxnqUNL1SEpNx7Nzd+JSbBICfMrivXsaq+Wfxa20ZrR10bEYPnw4fv/9d2zatCnPk39epPFs1aoVjh8/bvP3bm5u6rD1uMJ+gSjKY/XEDPVgHfTDDPUo7jr8vu88vlh/Ql1+776muLWhD/RaDz1/diU18CQ4q20b66AfZqiHGepQUvWYf8IReyId4eFkwUPVr2HjutUw8oy2s9bR7y+88AKWLFmCDRs2oE6dgufpTUtLw/79+9G7d+8SKSMRUWHsPXsNryzcqy4/dWsd9G9TU+siGVJJDjwJzmpnxzrohxnqYYY6lGQ95u8Ix9athyA5JqY+GoTbGlQ2/Iy2s9ajUPPmzcOyZctUSsELFy6o2729vVGmTBl1edCgQahRo4YaVRLvvPMObrnlFtSvXx/Xrl3DpEmTVLrZIUOGaFkVIqJMF6IT8fT3O9UUd5eAKhjTmxmg9DrwxFlt21gH/TBDPcxQh+KuR8iZq3hn+WF1eVSPANwRWA1mmNHWtGPx1VdfqZ+dO3fOdvu3336Lxx9/XF0OCwuDo+N/221cvXoVTz/9tOqEVKhQAUFBQdiyZQsCAwNLufRERLYzQEmnIjI2CQ2qlsUXA1rBSXIHUoFw4ImIzBys/dwPIUhJs6B3M18816kezELzpVA3IyNVWX322WfqICLSm/R0C15ZtAf7z0WjoqcrZg9ug3Luxh+l0wIHnojIjJJT01WnQgafGvqUxaQHW5hqvx1dBG8TEZnB5HXHsGL/Bbg4OWD6Y0GG3NxILzjwRERmNP63g9gVdg1e7s6YOTAYnm7m+ir+31APEREV2rI95/DFumPq8vv3NUPbEkwrS0RExjN/exh+/CdMBWt//nAr1K7sCbNhx4KIqIh2h13FqMX71OVnb6+LfsH+WheJiIh0ZFfYVYxblrGz9qvdA9ClUVWYETsWRERFcP5aAp7+PkStm+3auCpe69lI6yIREZGORMZmBGsnp6WjZxNfPN/ZPMHaObFjQURUSPHJqRjy3U5EXU9CI99ymPwwM0AREdF/ZNBp2I+7cDEmI1Pgxw+ZK1g7J3YsiIgKmQHq5QV7cCgiBpXLumLW4GCUNVkQHhERFc2E3w9hx+mrKOfmjBkDg0zfTrBjQURUCJ+sCcUfBy/C1clRNRZ+FZgBioiI/rNwx1nM3XYmI1h7QEvUrVIWZseOBRFRAS3ZHY5p60+oyx880AxBtZgBioiI/rPn7DWMXXpAXX65a0Pc0cgH9oAdCyKiAgg5cwWvL96vLksA3v2t/bQuEhER6cil2CQMnZsRrN090AfDu9SHvWDHgogon8KvxuPZfxuLHk18VMpAIiIiq5S0jGDtCzGJqFfFE5881AKOdpTUgx0LIqJ8uJ5kzQCVjMBqXvisf0u7aiyIiOjm3lt+GNtPX1FB2jMHBaOcuwvsCTsWREQ3kZZuwYj5e3DkQiyqlHNTGaA8XM2d2YOIiApmcUg45mw5rS7L4FM9OwjWzokdCyKim/jojyNYe/gi3Jwd8fWgYFQvX0brIhERkY7sC7+GMUsy4u9GdG2AboH2EaydEzsWREQ3sGjnWczYeFJd/ujB5mjpX17rIhERkY7IJqkqWDs1HV0bV8WLdzSAvWLHgogoDztOX8kcgXrhjvq4t2UNrYtEREQ6DNY+H52IulU88amdx9+xY0FEZMPZKxkZoFLSLOjdzFflISciIsrq/RWH8c+pf4O1BwbDy86CtXNix4KIKIfYxBQ89d0OXIlLRrMa3vikn32PQBERUW6/7ArHt39nBGtLWtn6Ve0vWDsndiyIiHJkgHrxp904evE6qpZzU8HaZVydtC4WERHpyIFz0Rj9S8ZS2RfvqI8eTXy1LpIuaNqxmDhxItq0aYNy5cqhatWq6Nu3L0JDQ2/6uEWLFqFRo0Zwd3dHs2bNsGLFilIpLxGZ38QVh7E+9FJmBihfb3eti0RERDpy+XqSWiqblJqOOxtVxQguldVHx2Ljxo0YNmwYtm3bhjVr1iAlJQXdu3dHXFxcno/ZsmULBgwYgKeeegq7d+9WnRE5Dhw4UKplJyLzWbgzHLM2n1KXP+7XAi2YAYqIiLJITUvH8Hm7ce5aAupUZrB2Tpru8LRq1aps1+fMmaNmLkJCQnD77bfbfMznn3+Onj17YtSoUer6hAkTVKdk6tSpmD59eqmUm4jM51i0A6b/czgzB/ndLaprXSQiItKZiSuPYOvJy/B0dcKMgUHwLmPfwdq6jrGIjo5WPytWrJjnfbZu3YquXbtmu61Hjx7qdiKiwjhzJR7fHHVEaroFdzWvhpfutN8c5HrBpbJEpDfL9pzH7H9ntSVYu6FPOa2LpDuazlhklZ6ejhEjRqBjx45o2rRpnve7cOECfHyy72Yo1+V2W5KSktRhFRMTo37Ksis5CsJ6/4I+Tm/MUA/WQT+MXg/JAPXM3F2IT3VAs+rlMLFvIFJTU2Fvn4XePj/rUlnpXMjnMWbMGLVU9tChQ/D09LzhUlnplNx1112YN2+e6pDs2rXrhu0KEdHNhMcBXyw7pC4P71IfPZtW07pIuqSbjoU0IBInsXnz5mJ9Xmlgxo8fn+v21atXw8PDo1DPKUuvzMAM9WAd9MOI9UizADMPO+JktCO8XS3oV+0q/lzzB+zxs4iPj4eecKksEemFpB6fHeqkgrU7B1TBy90YrK3rjsXw4cPx+++/Y9OmTfDz87vhfX19fXHx4sVst8l1ud2W0aNHY+TIkdlmLPz9/dXIl5eXV4FH9KSR6tatG1xcjLumzgz1YB30w8j1mLD8CI5Eh8Hd2RFPByTjwT7Gq0NxfRbW2Vy9yu9S2azne+tS2aVLl5Z4+YjIvMHaLy/chytJDqhZsQw+798KTgzW1mfHwmKx4IUXXsCSJUuwYcMG1KlT56aPad++PdatW6eWTVlJQyq32+Lm5qaOnKTRLewXiKI8Vk/MUA/WQT+MVo8ftp3B99vC1OVJDzZD+pkQw9UhL4Wph57rXVJLZQWXy2bHOuiHGephhjp8sCoUW05egaujBVMeagoPF2PWJ6WUlso6a738SdbALlu2TAXoWU/+3t7eKFOmjLo8aNAg1KhRQy1pEi+99BI6deqETz75BH369MH8+fOxc+dOzJw5U8uqEJGBbDkehbd/Paguv9q9IXo28cGKM1qXikp7qazgclnbWAf9MEM9jFqHXVEO+O5Yxgapj9ZPx+m9W3F6LwxtTQkvldW0Y/HVV1+pn507d852+7fffovHH39cXQ4LC4Oj43/Jqzp06KA6I2PHjlXBfA0aNFDT3AzMI6L8OBUVh+d+3KV22L63ZXUM61LfsMHa9qAkl8oKLpfNjnXQDzPUw8h1OBwRi9e//kfmTDGkY000Sz9pyHqU9lJZzZdC3YwskcqpX79+6iAiKojo+BQ8NWcHohNS0NK/PD58oDkcHLhWVo9KY6ms4HJZ21gH/TBDPYxWh6txyRg2fw8SU9JxW4PKeLV7AP5YddJw9dBiqawugreJiEpaSlo6hs3bhZNRcaju7Y6Zg4Lg7pIxxU36w6WyRKRVsPaL83fj7JUE1KzogSkDGKxt2A3yiIhKyoTfD2Hz8Sh4uDph1uA2qFrOXesi0U2WykomKFkqW61atcxjwYIFmfeRpbIRERG5lspKR6JFixZYvHgxl8oSUYFMWh2Kv45FoYxLxs7a5T1ctS6SoRRqxuLUqVP466+/cObMGRXQUaVKFbRq1UpNN8tup0REejJ362l8v/UMZNXTZ/1bIrB6wdbOU+njUlkiKm2/7zuPGRtPqsuT+jVH42psK0q0Y/Hjjz+qDYhkallS+FWvXl1NSV+5cgUnTpxQnYpHH30Ur7/+OmrVqlXgwhARFbe/jl3C/37L2C11VI8A9GiSdyAvERHZp8MRMRi1aJ+6/OztdXFX8+paF8ncHQuZkXB1dVXZmn7++WeVNSMryQMumxPJmtbg4GB8+eWXHDUiIk0dj7yO5//NAHV/6xp4rlM9rYtkF6Q9+Oeff3LNaucnAJuIqLRdi0/Gs3NDkJCSpoK1X+vZSOsimb9j8cEHH6gdTPMiWTVkLawc7733Hk6fPl1cZSQiKlRDMeS7HYhNTEVwrQqYeH8zZoAqYX///bea1f7tt99UakNroLXMaktno27dunjmmWcwdOhQFZBNRKQ1GXh6cf4ehF2Jh1+FMvjiYQZrl0rw9o06FTlVqlQJQUFBhS0TEVGRM0DJTMXpy/GoUb4Mpg8MgpszM0CVpHvuuQf9+/dH7dq11eZysbGxuHz5MsLDw9WsxbFjx9T+Q5IOtmHDhobdMIuIzOWT1aHYdPQS3F0cVbB2BU8Ga5d6Vqg5c+bYvF02mZLNhoiItAz6lV21t5y4DE9XJ8x+PBiVy+bep4CKl6R3lcQeH330EW677bbMlLBWMlsxePBgrFq1SnUusm58SkSkhRX7I/DlhhPqsuxr1KS6t9ZFMrxCndlffPFFFT9x9erVzNtCQ0PRrl07/PTTT8VZPiKiAvluy2nM+ydMZYD6YkArNPJlVo/S8Oyzz+Z7E6XAwEDceeedJV4mIqK8hF6IxauL9qrLT99WB/e2rKF1key3Y7F79241vd2sWTM1nT1t2jS0bt0ajRo1wt69GR8SEVFp23j0Et75PSMD1OhejXBnYx+ti2SX1q9fn+fvZsyYUaplISLKKTo+Bc/O3Yn45DR0qFcJrzNYW9uORb169VSQ3v3334+ePXvi5ZdfxqxZs1Q6WgnWIyIqbccjYzH8x11ItwD9gvzw9G11tS6S3ZJ2YdSoUSqA2yoqKgp333033njjDU3LRkT2TYK1X1qwOzMGb+ojreHsxKWZxaXQ7+Ty5ctValnZFK98+fKYPXs2zp8/X2wFIyLKr6txyXhyzk7EJqWibe2KePe+pswApfGMxZIlS9CmTRscOnRItRey+3VMTAz27NmjdfGIyI59tuYoNoRegptzRrB2RQZra9+xkLW0EmMhG+HJDtz79u1Te1zI0qiFCxcWbwmJiG4gOTUdQ38IUakC/SuWwVePtWYGKI116NBBdSCkMyHLZO+77z41sy07ZXPzVCLSyqoDEZi6/ri6/MEDzdC0BlfZ6KJjIcugZPOjV155RY0K+vr6YsWKFXjnnXfw5JNPFnshiYjyygA1btkB/HPqCsq6OWP24DaoxAxQunD06FHs3LkTfn5+cHZ2Vgk+JO0sEZEWjl2MxSsLM+KAn+xYB/e18tO6SKZUqI5FSEgIWrRokev2YcOGqd8REZWGb/4+jfk7zkL2MpoyoBUa+nDTNT2QDVVlmWy3bt1w4MABbN++XSX9aN68ObZu3ap18YjIzkQnpOCZuSGIS07DLXUrYnRvBmvrqmMhu2znJSAgoCjlISLKl/VHIvHe8owMUGN6N0aXRlW1LhL9S3bfXrp0KaZMmQJ3d3e1JEo6F5Lwo3PnzloXj4jsSHq6BS8v2INTUXGo7u2OaY+0hguDtUuMY0GyfGzbtu2m95PdVj/88EOVgpaIqKSmtF/4abfKANU/2B9P3VpH6yJRFvv370evXr2y3SZ7XEyaNEntyk1EVFomrzuGP49E/husHczlsiXMOb93lGDtBx54QKWTlZSBwcHBqF69uhqNko3yJPPH5s2bVayF7MAqDQgRUXG7IhmgvtuB65IBqk5FTOjLDFB6U7ly5Tx/16lTp1ItCxHZrz8OXsAX646py+/f1wzN/BisrZuOxVNPPYXHHnsMixYtwoIFCzBz5kxER0er30mjLjup9ujRAzt27EDjxo1LssxEZOcZoM5eSUDNih6Y/lgQXJ05pa0HQ4cOxdixY1Ww9s1IG5KamopHH320VMpGRPa5t5E1WPvxDrXxQBCDtXXVsbDGVkjnQg4hHYuEhARUqlRJTXMX1KZNm9TMhgR8R0REqLznffv2zfP+kqqwS5cuuW6Xx0pmKiIydwaot5YewPZ/M0DNGhzM/OM6UqVKFTRp0gQdO3a84ay27H8kt8vgFBFRSYhJzAjWlpntdnUq4s0+HPDWZcciJ1kWVZSdtuPi4lR2KUlRK0F9+SVpC728vDKvV63KoE0ie8gAtWDnvxmgHmEGKL2ZMGEChg8fjlmzZuHLL79UHYmsypUrh65du6oOhcTsERGVVLD2yAV7cPJSHKpJsPajDNbWbcfiiy++sHm7dC4aNmyo0gsWhAT35Qzwyw/pSMhu30RkH9aH5sgAFcDBBD3y8fHBm2++qQ6ZpQgLC1Oz2hJzUa9ePcbCEFGJ++LPY1h7OFItk5XlspUZrK3fjsVnn31m8/Zr166pZVGy2+qvv/6KihUroiS1bNkSSUlJKoXh//73PzX1nhe5nxxWMTEx6mdKSoo6CsJ6/4I+Tm/MUA/WwX7qcTzyOl6Yl5EBql9QDQxq51fsr8XPovjrXqFCBXUQEZWWNYcuYvLajGDt9/o2RQt/DkLrumNx6tSpPH938uRJFXshwXsyDV4SqlWrhunTp6u1u9JZkCl3yYkuu4C3bt3a5mMmTpyI8ePH57pdUh56eHgUqhxr1qyBGZihHqyDuesRlwJ8ut8J15McUK+cBbc4n8HKlWdQUuz5syiOXbFlYOlGs9pyDi8IxuERUX6duHRdLYESg9vXQr9gf62LZJeKFGORVd26ddVuqxIvUVJk872sG/DJDMmJEyfUTMrcuXNtPmb06NEYOXJkthkLf39/dO/ePVucRn5H9KTBlt1kCxOsrhdmqAfrYP56pKSl48nvQhCVdBV+Fcpg3rPtSixYm5/Ff7O5RXGjL/2yDOrhhx/G119/ne9BHcbhEVF+xEqw9vc7EStpyGtXxNi7ArUukt0qto6FqFmzJi5cuIDS1LZtW5Vp5EaZrGztFC6NbmG/QBTlsXpihnqwDuatx/jl+7Ht1FV4ujrhm8fbwKe8J0qaPX8WxVHv9PR0m7fLUlmZdRg2bBjeffddvP/++/l6PsbhEVF+grUlreyJS3Hw9XLH1EdbMVhbQ47FvdtqrVq1UJr27NlT4Ol1ItK3uVtP44dtYZBY388fZgYoo5OlUHfccYeaXf7ll19K/PUkDk/aBZm5+fvvv0v89YhIO9PWH8fqQxfh6uSI6QODULWcu9ZFsmvOxTFVbh2NeuWVVzB48OB8P9/169dx/PjxbDEc0lGQ4G+Z/ZBlTOfOncP333+vfj958mTUqVNH5UpPTExUMRZ//vmnipcgInPYcjwK//stIwPUaz0aoWugj9ZFomLSqFEjhIeHl9jzFyYOjwk+smMd9MMM9SjpOqwPvYRP1x5Vl/93d2M08fUskdey988ipQCPKVDHQqaW80oXKLcPGTIEb7zxRr6fb+fOndkC7ayxENI5mTNnjgq4k3SFVsnJyarzIp0NWaPbvHlzrF271mawHhEZz5nLcXh+3i6kpVtwX6saGNqprtZFomIkST5kczw9xeExwYdtrIN+mKEeJVGHyISM5B4WiwM6+qTD8+JerFiRsdN2SbHXzyK+AMk9CtSxWL9+vc3bJUiuQYMGaofVyMjIfDccMpIku+nmRToXWb322mvqICJzBt8N+W4nrsWnqBSBE+9vxn0PTERmo1999VX06dNHV3F4TPCRHeugH2aoR0nVQXbU7jfjHySkxSGoZnnMfCJY7VtRUuz9s4gpQHKPAnUsOnXqdMPf7927V003p6WlFeRpicjOSfDdywv24ljkdVQt54aZA4Pg7uKkdbGogGTfCludQcnulJqaqho02XtIT3F4TPBhG+ugH2aoR3HWQQakR8/fh+OX4uDj5YavBgbBs0zpbIJnr5+FSwHuX6xZoYiICuOztUex9vBFNeI0c1AwfLwYfGdEEgdni4z8yxKlwMCCpYBkHB4R5fTlhhNYdfACXJwc8NVjDNbWG3YsiEhTK/ZHYMqfGV8eP7i/GVpyp1TDulnyjn379qnAaomXyw/G4RFRVutDI/Hx6lB1efw9TdG6ZgWti0Q5sGNBRJo5HBGj8o+Lp2+rg/tb+2ldJCpBsoShIEtlGYdHRFano+Lw0k+7IaeEAW1r4pF2NbUuEhW1YyGjTTfb7ZSIKD+uxiXjmbk7kZCShtsaVMbrPRtpXSQiItKhuKRUPDs3BDGJqWhVszz+dw931jZFx0I2HZLAPFsjSNbbmcWFiG4mNS0dL/y0G2evJKBmRQ9MGdAKztwplYiIcpDvlq8t3ofQi7GoUs4N0x8Lgpszk3uYomMhgXNEREU1aXUoNh+PgoerE74eFIzyHq5aF4mKwc1SEsbGxpZaWYjIHKZvPInl+yMygrUfbc3kHmbqWNSqVavkSkJEduH3fecxY+NJdXnSgy0Q4FtO6yJRMbnRJqqCs9pEVBAbj17CR38cUZffvrsJgmtX1LpIVJwdi48++ggvvPACypQpo67//fffKsOHNQe4jEa9/vrr+PLLLwvytERkJ0IvxGLUooxYraGd6qFP87z3FyDjyWsTVSKigjpzOQ4v/hus3T/YH48yWNt8HQvJGf74449ndix69eqlcorXrVs3c8vvGTNmsGNBRLnEJKZg6A8hKlj71vqVMapHgNZFomJ2s01UiYjyIz45I1g7OiFFpSB/p28TznYaRIGiJXMGbd8oDSARUdZzxasL9+JUVBxqlC+DLwa0gpMjGwmzWbhwYbY9KsLDw5Genp55XQafZOabiOhmwdpHLsSiclk3fPVYawZrGwjTsBBRqQTfrT50Ea5Ojvjy0dao6MlgbTMaMGAArl27lnlddto+ffp05nVZLisz30REefn6r5P4fV8EnB1lZ+3WqOadsUqGjIEdCyIqUVtPXMYka/DdPYFowZ21TYuz2kRUFJuPReGDldZg7UC0YbC2+XfenjVrFsqWLasup6amqp1PK1eurK4zlSARZRUZm4gX5+9GugV4oLUfHmnL4DsiIsrt7JV4DP9pl2ovHgr2w2O3MBOp6TsWNWvWxNdff5153dfXF3Pnzs11HyKitHQLXvppDy7FJiHApxze7duUwXdERJRLQnIanpkbgmvxKWjh54137mV7YRcdi6xrZYmIbuTztUex9eRltQnetEdbo4wrg+/swR9//AFvb291WQK3161bhwMHDqjrWeMviIisSyZf/3kfDkfEoHJZV0wfGAR3F7YXdtGxSExMxNq1a3HXXXep6xKEl5SU9N+TOTvjnXfegbs7d0Uksvd1slPWH1eXJ97fDPWrZiyfJPMbPHhwtuvPPvusZmUhIv2bvfkUft17XgVrT3uEwdp21bGQeIrly5dndiymTp2KJk2aZO5rceTIEbU8auTIkSVTWiLSPVn6NGLBHrWp0SPtauLeljW0LhKVkqypZfMiKWeJiMSW41F4f8VhdXlsn8ZoV7eS1kWi0swK9eOPP+KZZ57Jdtu8efPUbqtyTJo0CYsWLcr3823atAl33303qlevrtbSLV269KaP2bBhA1q3bq12+65fv77q7BCRPqSnWzBy4R5EXc+Iqxh3V6DWRSKdkNntTz/9NHNDVSKybxKsPWzerszkHoM71Na6SFTaHYvjx4+jWbNmmddlyZOj439P0bZtWxw6dCjfzxcXF4cWLVpg2rRp+br/qVOn0KdPH3Tp0kXt+D1ixAgMGTJEreklIu3N2HQSfx2LgruLI6Y+0orrZO2w8yBLZIODg9GhQ4fMwaJvvvkGderUwWeffYaXX35Z62ISkQ6CtWVn7avxKWju54337mOwtl0uhZLAu6wxFZcuXco1DZ719zfTq1cvdeTX9OnTVeP0ySefqOuNGzfG5s2bVWPVo0ePfD8PERW/PWev4ePVoery+HuaoIFPOa2LRKVs3LhxmDFjBrp27YotW7agX79+eOKJJ7Bt2zY1WyHXnZzY2SSy92DtMUv241BEDCp5umL6YwzWttsZCz8/v8zsHrbs27dP3aekbN26VTVYWUmHQm4nIu0kpgEjF+1XKWbval4NDwX7a10k0oAshf3++++xePFirF69GmlpaWq/o7179+Lhhx9mp4KI8M3fp7Fk9zk4OTpg6iOtUb08g7Xtdsaid+/eakRKliPlzPyUkJCA8ePHq9+VlAsXLsDHxyfbbXI9JiZGvb41iDwrmUHJOosi9xUpKSnqKAjr/Qv6OL0xQz1YB/2Q8v98yhFnryagurc7xt/VSH2ZNBIzfRZZfxbmsUURHh6OoKAgdblp06YqFk6WPnGJAxGJLSeyB2u3r8dgbbvuWIwZMwYLFy5EQEAAhg8fjoYNG6rbQ0NDVYYo+TIh99GTiRMnqg5PTjKa5uHhUajnXLNmDczADPVgHbS3O8oB2y85wQEWPOh3HZvXG7c+Rv8silKP4sjWJDMUrq6u2VKQly3LVMNEBJy7loDh83arme37W9XA4wzWNqUCdSxkdkDWzT733HN444031Do5IaNR3bp1w5dffplrRqE4SSrbixcvZrtNrnt5edmcrRASSJg1/a3MWPj7+6N79+7qcQUd0ZMGW+rq4uICozJDPVgHfYiITsRbU7cASMWzt9XGC90DYERm+CyKWg/rbG5RSJvw+OOPq5kK695HQ4cOhaenZ7b7/fLLL/nOHCjZBkNCQhAREYElS5agb9++N80cKOf8gwcPqnP92LFjVZmISDuJKRKsvRNX4pLRtIYX3r+/GWcyTapAHQshwdOrVq3ClStXVJYoIWlfK1asiJLWvn17rFixIttt0ojK7XmRBs7ayGUljW5hv0AU5bF6YoZ6sA7appYdvfQgYhJTUausBS/e2cCQ9TDDZ1Ec9SiOeufcHO+xxx4r0vNZMwc++eSTuP/++/OdOVA6M5IeXXb9lsyB1apVY4IPIo3IGPS4Xw/hwLkYVGSwtukVuGNhJR0JSS9bFNevX8/snFgbBUkjK89ds2ZNNdtw7tw5FQwopLGQJVevvfaaamj+/PNPtTRLNu0jotI1Z8tp/H38Msq4OOKx+slwcSpQLggyoW+//bZYn4+ZA4mM768LDlhyOuLfYO1W8KtQuGXoZPKORXHYuXOn2pPCyrpkSUa9ZOM7mfoOCwvL/L00GNKJkGDAzz//XGWgmjVrFhsMolJ27GIsPlx1RF1+vWcAKkTt17pIRHlmDpQ9j/LCBB/ZsQ76YYZ6bDkWiSWnMwadXu/REG1qehuyPmb4LFJKKbmHph2Lzp07Z8Zp2GJrV215zO7du0u4ZESUl5S0dLy8cA+SUtPRqWEVPNLGDytXsmNB2itM5kAm+LCNddAPo9bjahLw8T4npMMBQZXTUfXqQaxYcRBGZtTPojSTe2jasSAi45ny53G1Vra8hwsmPdicAXhkaEzwkR3roB9GrkdSShoGzN6B66kxqOFhwcynO8PLI/s2BUZi5M+itJN7sGNBRPm2L/wapq3PiIt6t29TVPVyN/TUMJlLYTIHMsGHbayDfhitHmpn7aWHsF8GoMq44KmABNWpMFIdzPJZaJHcg9GWRJTvdIEjF+7N3F37rubVtS4SUTaSIVAyQRUkcyARFa8ftp3BopBwODoAk/s3RyXjTlRQIbBjQUT58umaozgeeR2Vy7phwr1NtS4O2QHJHCiZAuXImjnQmtRDljENGjQo8/6SOfDkyZMqc+CRI0fU3kqSOVASfhBRydt+6grG/3ZIXX6jVyN05M7adocdCyK6qZ2nr+Drv06qyx/c3wwVPP/bXZmoJDMHtmrVSh1CYiHk8rhx49T1vDIHyiyF7H8haWeZOZCodEREJ+D5H0OQ+u+s9tO31dW6SKQBxlgQ0Q3FJ6fi1UV71SZHD7T2Q9fA7Fl3iEoKMwcSGWep7NAfdiHqejIa+ZbDR0zsYbc4Y0FEN/TRqlCcvhwPXy93jLs7UOviEBGRjkjn/+1lB7H37DV4l3HBzIHB8HDluLW9YseCiPK07eRltcO2+PDB5qrRICIisvrxnzAs2HlWBWtPGdAKNStxZ217xo4FEdkUl5SKUYv3qssD2vqrzfCIiIiyxt+N/y1j07vXejbC7Wwn7B47FkRk08SVh3H2SgJqlC+DMb0ba10cIiLSkQvRiSquIiXNgj7NquHZ2xmsTexYEJENm49F4YdtGdl2JAivnDuXQBERUYak1DQ892MIoq4nIcCHwdr0H3YsiCib2MQUvPbvEqiBt9RCx/qVtS4SERHpyP9+PYjdYdfg5e6MGQOD4OnGYG3KwI4FEWXz7u+HcT46ETUreqgNjoiIiKzm/ROGn7afhUxQfDGgFWpX9tS6SKQj7FgQUab1RyJVdg9pMCY92JyjUERElCnkzFW8/esBdfnV7gHoHFBV6yKRzrBjQUTK1bhkvPbzPnX5yY510K5uJa2LREREOnExJhHP/RCigrV7NfXF853raV0k0iF2LIhIbXA0dukBXIpNQv2qZTGqR4DWRSIiIp1ITk1XnYrI2CQ0qFoWk/q1YLA22cSOBRHh173nsXx/BJwdHfDZQy3h7uKkdZGIiEgnZK+KXWHXUM7dGTMHBaMsl8lSHtixILJzEdEJeGtpxprZF+5ogGZ+3loXiYiIdGL+9jC1u7YK1n64FeowWJtugB0LIjuWnm7ByAV7EZOYihZ+3ni+C9fMEhFRhl1hVzFuWcbO2iO7NkSXRgzWJgN0LKZNm4batWvD3d0d7dq1w/bt2/O875w5c9S6vqyHPI6ICu7rv05i68nLKOPihM/6t4SLky5OCUREpLHI2Ixg7eS0dPRo4oNhXeprXSQyAM2/RSxYsAAjR47E22+/jV27dqFFixbo0aMHIiMj83yMl5cXIiIiMo8zZ86UapmJzODAuWh8vDpUXX777kDUrVJW6yIREZFOgrWH/bgLF2MyEnp88lBLODoyWJsM0LH49NNP8fTTT+OJJ55AYGAgpk+fDg8PD3zzzTd5PkZmKXx9fTMPHx+fUi0zkdElJKfhpfm7VdpAGYnq38Zf6yIREZFOTPj9EHacvopybs6YOTCIwdqUb5r+T0lOTkZISAhGjx6deZujoyO6du2KrVu35vm469evo1atWkhPT0fr1q3x/vvvo0mTJjbvm5SUpA6rmJgY9TMlJUUdBWG9f0EfpzdmqAfrUDRvLT2IE5fiULWcGybc0xipqamFfi5+Fuaoh9HrTkTFY+GOs5i7LWMliCyR5Ww2GaZjERUVhbS0tFwzDnL9yJEjNh8TEBCgZjOaN2+O6OhofPzxx+jQoQMOHjwIPz+/XPefOHEixo8fn+v21atXq5mRwlizZg3MwAz1YB0KbsclByw+7gQHWPCQfzy2blhbLM/Lz8LY9YiPjy+RshCRcew5e03taSRe7toQXQO5IoQKxnBzW+3bt1eHlXQqGjdujBkzZmDChAm57i+zIRLDkXXGwt/fH927d1exGgUd0ZMGu1u3bnBxcYFRmaEerEPhnLwUh9HTtwFIw/Au9fDiHUUPxuNnYY56WGdzicg+yQapQ+dmBGt3C/TBC8XQPpD90bRjUblyZTg5OeHixYvZbpfrEjuRH9J4tmrVCsePH7f5ezc3N3XYelxhv0AU5bF6YoZ6sA75l5iShhGL9iM+OQ231K2IEd0awakYg/H4WRi7HmaoNxEVTkpaOobN24ULMYmoW8UTnz7UgsHaZLzgbVdXVwQFBWHdunWZt0nchFzPOitxI7KUav/+/ahWrVoJlpTI2CwWC95ccgCHI2JQydMVnz/cqlg7FUQlhenIiUree8sPY/upKypIe+bAYJRz50ADGXQplCxTGjx4MIKDg9G2bVtMnjwZcXFxKkuUGDRoEGrUqKFiJcQ777yDW265BfXr18e1a9cwadIklW52yJAhGteESL9++CcMP+8Kh/QlpgxoBR8vftki/bOmI5dsgdKpkPZB0pGHhoaialXbG3XJElf5vZV0Logob4tDwjFny+nMYG1JL0tk2I5F//79cenSJYwbNw4XLlxAy5YtsWrVqsyA7rCwMJUpyurq1asqPa3ct0KFCmrGY8uWLSpVLRHlFnLmKt75LWPn1Nd7NkKH+pW1LhJRgdORC+lgLF++XCXweOONN26YjpyIbm5/eDTGLNmvLr90ZwMVW0Fk6I6FGD58uDps2bBhQ7brn332mTqI6OYiYxLx/I8har+K3s188cztdbUuEpFu0pELpiTPjnWwn3pcjkvGM3N3qs3w7giogudvr13sr8XPwv7SkeuiY0FEJbMJ3pDvd2bunPrRgy24LIQMozTSkQumJLeNdTB3PdLSgS8POyIixhFV3S3o7hWBVasiUFL4WdhPOnJ2LIhMKD3dglcW7cG+8GhU8HDB7MHB3DmVTK+g6cgFU5JnxzrYRz3eW3EEx2PC4OnqhO+ebldicRX8LOwvHTm/aRCZ0KdrjmLF/gtwcXLAjIHBqFXJU+siEekuHblgSnLbWAfz1mPJ7nDM2RqmLn/yUEs0rlEBJY2fhf2kI9c03SwRFb/528MwdX3GF6n372uGtnUqal0kogJjOnKi4nfgXDTe+DkjWHt4l/ro2ZSJDqh4ccaCyERWH7yQmeFDGo1+wf5aF4mo0JiOnKj4XIlLxrNzQ5CUmo4uAVXwcreGWheJTIgdCyKTkM2NXvhpN9ItwEPBfnilOxsNMjamIycqHqlp6Rg+bxfOXUtA7UoemMxNUqmEsGNBZJLp7SHf7VAjUV0bV1VLoJgBisyA6ciJiu6DlUew5cRleLg6YeagYHiXMXacAOkXYyyIDO7Q+Rg8NvsfxCSmok3tCpgyoDWcnfinTUREwLI95zBr8yl1+eN+LdDQp5zWRSIT47cPIgMLvRCrOhXX4lPQ0r88vnm8Dcq4OmldLCIi0oGD56Px+s/71OXnO9dD72ZMZEAlix0LIoM6HBGDR2dtUwF5zf288d2TbVHOndPbREQEXP03WDsxJR2dGlbBK90DtC4S2QHGWBAZ0O6wqxj8zXa1/KlJdS98/2RbrpklIqLMYG1J5hF+NQE1K3rgCwZrUylhx4LIYLaciMKQ73YiPjkNQbUqqOVP7FQQEZHVpD9Csfl4FMq4SLB2ELw92EZQ6WDHgshAft93HiMX7kVyajpurV9ZNRgervwzJiKiDL/uPY8Zm06qy5P6NUcjXy+ti0R2hN9IiAzAYrFg+saT+HDVEXW9RxMffP5wK7i7MFCbiIj+i717bfFedXlop3q4q3l1rYtEdoYdCyKdS0lLx9u/HsS8f8LU9Sc61sbYPoFcL0tERJmuxSfjmbk7VbD2bQ0qY1QPBmtT6WPHgkjHLsUmYdiPu7D99BXIfndv9QnEk7fW0bpYRESkI2npFhWsffZKAvwrlmGwNmmGHQsindp79hqG/hCCiOhElHVzxuT+LdE10EfrYhERkQ6Dtf869m+w9sBgVPB01bpIZKfYsSDSYTzF91vP4L3lh5Gclo66VTxVQ1G/almti0ZERDqzfF8Epm88oS5/+GBzNK7GYG3SDjsWRDpbI/va4n1Yfeiiut4t0AefPNQCXtz4joiIcjhyIQavLsoI1n7m9rq4pwWDtUlbuth5e9q0aahduzbc3d3Rrl07bN++/Yb3X7RoERo1aqTu36xZM6xYsaLUykpUUv4+HoXen/+lOhUuTg4Yd1cgZg4MYqeCiIhyiY5PUTtrJ6SkqfTjrzFYm3RA847FggULMHLkSLz99tvYtWsXWrRogR49eiAyMtLm/bds2YIBAwbgqaeewu7du9G3b191HDhwoNTLTlQc4pNTMW7ZATw66x+cj05ErUoe+OW5jipI20EitomIiHIEa784fzfOXI6HX4UymDKgFZydNP9KR6R9x+LTTz/F008/jSeeeAKBgYGYPn06PDw88M0339i8/+eff46ePXti1KhRaNy4MSZMmIDWrVtj6tSppV52oqI6cs0Bd0/bqmIqxGO31MSKF29DMz9vrYtGREQ69emaUGw8egnuLo6YMTCIwdqkG5rGWCQnJyMkJASjR4/OvM3R0RFdu3bF1q1bbT5GbpcZjqxkhmPp0qU275+UlKQOq5iYGPUzJSVFHQUR9N6fiE10woitqwEjDyRb5J/C1SPn3a0j6vKvXJTrkuHOUf10gLOjg0p55+zkAFcnR7g6O8LN2REerk7qkGxH3mVc1FHR0xVVy7mpo3p5d/h6ueeZLs/62RX0M9RTGtn3VhzG8sOywV0CfL3cMPG+pri1fiX1ARmpXkb/LMxSh6LWw+h1J7IXK/dHYNr6f4O1H2iOJtU5EEX6oWnHIioqCmlpafDxyZ5CU64fOZKxw3BOFy5csHl/ud2WiRMnYvz48bluX716tZoZKYiUFCdYrF+t1ZdzIytcPXLd3ZLzluJ7Y5wcLKjsDviUsaCGhwU1PIGaZS3wzjIws2bNGhhJSjqwKcIBq885IjHNAQ6w4DZfC/r4xyHm6D9YcRSGZbTPwqx1KGw94uPjS6QsRFR8jl6MxSv/BmsPubUO7m1ZQ+siEdlXViiZDck6wyEzFv7+/ujevTu8vAqWkq11hzhs2LARnTp1gouLcd+6lJRUbNy4Ebd3uh0uzoULDLZkSY1qydK/kOvpFiBNfqZb1DrQ1H9/Jqemq/SpiSlpiE9OUwFnsYmpiElIxbWEFFyOS0ZkbBIuxiSqvRtS0oCLCXI4YN+V/15b1pMG+XvDI+4cnrn7NvhV0n8aVnkvVh68iMmrjyL8WqK6rUm1cuhV+SqevK8bXFyMG6AtI93yRbZbN+PWwwx1KGo9rLO5RKRP0QkpeOb7nar97FCvEt7o1UjrIhHloum348qVK8PJyQkXL2ak1rSS676+vjYfI7cX5P5ubm7qyEka3YI2vL7lPeHlClSr4Gn4Lx9Sj+oVyuq2HtIROX8tAacvx+Hoxes4dD4GB89Hq9Ga8KsJ6pDlXD9N3oIAn3LoHFAF3Zv4oKV/BV3tNiodilUHL+DztccQejFW3ebj5YZRPRrh7qZVsWrVykL9X9QjM9TDDHUobD3MUG8is5I2ccT83Th9OR41ypfB1EdaM1ibdEnTjoWrqyuCgoKwbt06ldlJpKenq+vDhw+3+Zj27dur348YMSLzNhmhk9vJPKRz4F/RQx23NaiSeXtsYgp2h13DthNRWB5yAmFxDuoLuxwzNp1E5bKu6NrYB72aVUP7upVUTIcWZFZm6e5zmL35FI5FXle3lXN3xtO31cWQ2+rAw9WZa9qJiChfJq89ivWhl1SMogRrS0wikR5pvp5HlikNHjwYwcHBaNu2LSZPnoy4uDiVJUoMGjQINWrUULES4qWXXlJLkT755BP06dMH8+fPx86dOzFz5kyNa0KloZy7C25vWAXt65RHQPJRtO/cFdtOR2Pd4Yv480gkoq4nY/6Os+rwcndWnYzuTXzRqWEVlHGVQOmSdTzyOn7eFY7528NwNT4ls0PxZMc6Kn2sBKkTUcH2OZo0aZKKo5N05FOmTFFtxY32OXrrrbdw+vRpNGjQAB9++CF69+5dqmUmKk6yt9GUP4+ryx880AxNazBYm/RL845F//79cenSJYwbN041HC1btsSqVasyA7TDwsJUpiirDh06YN68eRg7dizGjBmjGg7JCNW0aVMNa0FaqeDhqnYalUNiOLadvKyWHq0+eEF1Mn7ZfU4dkpLv1vpV0CmgCjo3rKJmQorL6ag4rDsSiV/3nMPe8OhssSCPd6iNfsH+7FAQFWGfI0lDLpunysCTZAEMDQ1F1apV89znSAai7rrrLtVWyGy47JHENoKM6FwcMO3njH26ZIDqvlZ+WheJSN8dCyHLnvJa+rRhw4Zct/Xr108dRFnJsieZzZBjwr1NsfP0FTXS88fBCyomY+3hi+oQsgldUM0KCKpdAc1qeKNulbIq9W1+1rnKrMS+8GvYFx6NzcejcCoqLvP3kl5XZkekM9Et0EdX8R5ERpN1nyMhHYzly5erfY7eeOONG+5zJGSfI1kqK/scyWOJjCIpNQ3T/jyBafudkGZJwy11K2JMbwZrk/7pomNBVNzkC327upXUMbZPYxyKiMGG0EvYGHoJIWFX1W6lcshshpUEVVfzLoPyHhn7ajg7OiIlLV3NhFyJS8a5awkqY5VkucrKxckBbWpXVB2Ju1tUR+WyuZMFEJH+9jkqzr2ONh+/jN/3nce5c47Y9Mv+bDPtRiJxjqyD9kLOXMXJKEkB7YBb61XEJ/2aw5KehpT0NBgJ9wiyv32O2LEg05NN+2QDITmGdamPmH8DwOXEHXLmCkIvXEfUdUlzm3HcjGzsJ2tcm9fwRnDtiuhYv5KK/SAiY+1zVJx7HW2IcMCS0xLH5QhERsDYWAc9KOdiwf2109GqUiS2bVwLI7PnPYLsbZ8jdizI7ni5u6jlSnJkzQ8uS5oiYxLVnhrR8SlIt1jg4uSoZiS8yrioFH/Vy5eBzw12BCci+9zryC88GrWOXcLx48dQv34DOBl0pDwtPZ110AFPN2f0CqyM7Zs3GHp/He4RZH/7HLFjQQSopU8t/ctrXQwiKsV9jopzr6OgOpXR3M8bKxKOoneX+ob+8sE66IN1+YkZ9tcxQx3MUg+XEt7nyJhdeSIiMrWs+xxZWfc5ymvfIus+R1lxnyMiotLDGQsiItIl7nNERGQs7FgQEZEucZ8jIiJjYceCiIh0i/scEREZB2MsiIiIiIioyNixICIiIiKiIrO7pVAWi6XAOXmzpn6TTULksUZON2aGerAO+mGGepihDkWth/WcaD1H2it7byNYB/0wQz3MUAez1COllNoHu+tYxMbGqp+yARIREeU+R3p7e8NesY0gIip8++BgsbPhKcmDfv78eZQrVw4ODgXbPdm6I+vZs2cLtCOr3pihHqyDfpihHmaoQ1HrIU2BNBrVq1fPlmnJ3th7G8E66IcZ6mGGOpilHjGl1D7Y3YyFvCF+fn5Feg75QIz6H8ts9WAd9MMM9TBDHYpSD3ueqbBiG5GBddAPM9TDDHUwSz28Srh9sN9hKSIiIiIiKjbsWBARERERUZGxY1EAbm5uePvtt9VPIzNDPVgH/TBDPcxQBzPVw6jM8P6zDvphhnqYoQ5mqYdbKdXB7oK3iYiIiIio+HHGgoiIiIiIiowdCyIiIiIiKjJ2LIiIiIiIqMjYsSike+65BzVr1oS7uzuqVauGgQMHqk2VjOT06dN46qmnUKdOHZQpUwb16tVTgT3Jyckwkvfeew8dOnSAh4cHypcvD6OYNm0aateurf4PtWvXDtu3b4eRbNq0CXfffbfaMEc2Elu6dCmMZuLEiWjTpo3aDK1q1aro27cvQkNDYSRfffUVmjdvnpmbvH379li5cqXWxbJ7Rm8jzNI+GLWNYPugPTO0D1q0EexYFFKXLl2wcOFC9Z/s559/xokTJ/Dggw/CSI4cOaJ2mZ0xYwYOHjyIzz77DNOnT8eYMWNgJNLQ9evXD8899xyMYsGCBRg5cqRqqHft2oUWLVqgR48eiIyMhFHExcWpcksDaFQbN27EsGHDsG3bNqxZswYpKSno3r27qptRyGZuH3zwAUJCQrBz507ccccduPfee9XfNGnH6G2EWdoHI7YRbB/0wQztgyZthGSFoqJbtmyZxcHBwZKcnGwxso8++shSp04dixF9++23Fm9vb4sRtG3b1jJs2LDM62lpaZbq1atbJk6caDEiOZUsWbLEYnSRkZGqLhs3brQYWYUKFSyzZs3SuhhksjbCyO2DkdoItg/6ZJb2oaTbCM5YFIMrV67gxx9/VFOtLi4uMLLo6GhUrFhR62KYmoyeychB165dM29zdHRU17du3app2eyd/P8XRv0bSEtLw/z589WImkx3kz6YpY1g+1Dy2D7ol9Hbh9JqI9ixKILXX38dnp6eqFSpEsLCwrBs2TIY2fHjxzFlyhQ8++yzWhfF1KKiotQft4+PT7bb5fqFCxc0K5e9k2UfI0aMQMeOHdG0aVMYyf79+1G2bFm18dHQoUOxZMkSBAYGal0su2emNoLtQ+lg+6BPRm4fSruNYMciizfeeEMFGd3okHWnVqNGjcLu3buxevVqODk5YdCgQbK0DEarhzh37hx69uyp1qE+/fTTMGIdiIpC1tIeOHBAjeYYTUBAAPbs2YN//vlHrSMfPHgwDh06pHWxTMcMbYQZ2gfBNoJKk5Hbh9JuI7jzdhaXLl3C5cuXb3ifunXrwtXVNdft4eHh8Pf3x5YtWzRfglDQekimks6dO+OWW27BnDlz1LSrET8LKbuMKFy7dg16n+qW7CSLFy9WWSas5A9dym7EUU1pxGUEJGt9jGT48OHqfZdMJpIFx+hk2YRk8ZHAWyo+ZmgjzNA+mLmNYPugP2ZrH0q6jXAu9mc0sCpVqqijsNNkIikpCUaqh4xESfaSoKAgfPvtt7ppNIryWeidNHTyfq9bty7zRCv/f+S6nMCo9Mi4ygsvvKAavQ0bNpim0ZD/T3o4F5mNGdoIM7QPZm4j2D7oh1nbh5JuI9ixKASZStqxYwduvfVWVKhQQaURfOutt1TvT+vZioKQRkNGomrVqoWPP/5YjQBZ+fr6wihk7bIER8pPWZsq032ifv36ak2hHkkqQRmBCg4ORtu2bTF58mQVTPXEE0/AKK5fv67WXVudOnVKvfcS2Cb5+40yvT1v3jw1GiW5yq1rmL29vVXufiMYPXo0evXqpd7z2NhYVR9pBP/44w+ti2a3zNBGmKV9MGIbwfZBH8zQPmjSRpRIrimT27dvn6VLly6WihUrWtzc3Cy1a9e2DB061BIeHm4xWuo9+S9g6zCSwYMH26zD+vXrLXo2ZcoUS82aNS2urq4qveC2bdssRiLvr633XT4Po8jr/7/8bRjFk08+aalVq5b6f1SlShXLnXfeaVm9erXWxbJrZmgjzNI+GLWNYPugPTO0D1q0EYyxICIiIiKiItPPgkkiIiIiIjIsdiyIiIiIiKjI2LEgIiIiIqIiY8eCiIiIiIiKjB0LIiIiIiIqMnYsiIiIiIioyNixICIiIiKiImPHgoiIiIiIiowdCyIiIiIiKjJ2LIiIiIiIqMjYsSAiIiIioiJjx4KolF26dAm+vr54//33M2/bsmULXF1dsW7dOk3LRkRE2mH7QEbnYLFYLFoXgsjerFixAn379lUNRkBAAFq2bIl7770Xn376qdZFIyIiDbF9ICNjx4JII8OGDcPatWsRHByM/fv3Y8eOHXBzc9O6WEREpDG2D2RU7FgQaSQhIQFNmzbF2bNnERISgmbNmmldJCIi0gG2D2RUjLEg0siJEydw/vx5pKen4/Tp01oXh4iIdILtAxkVZyyINJCcnIy2bduqtbOyhnby5Mlqurtq1apaF42IiDTE9oGMjB0LIg2MGjUKixcvxt69e1G2bFl06tQJ3t7e+P3337UuGhERaYjtAxkZl0IRlbINGzaoEai5c+fCy8sLjo6O6vJff/2Fr776SuviERGRRtg+kNFxxoKIiIiIiIqMMxZERERERFRk7FgQEREREVGRsWNBRERERERFxo4FEREREREVGTsWRERERERUZOxYEBERERFRkbFjQURERERERcaOBRERERERFRk7FkREREREVGTsWBARERERUZGxY0FEREREREXGjgUREREREaGo/g83OLEHolWIhgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# create 100 sample data points in range -3, 3\n",
    "x = torch.linspace(-3,3,100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8,3))\n",
    "for i, (y,label) in enumerate(zip([y_gelu, y_relu],[\"GELU\", \"RELU\"]),1):\n",
    "    plt.subplot(1,2,i)\n",
    "    plt.plot(x,y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2,3,768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Feed Forward with shortcut connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_size, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_size[0], layer_size[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_size[1], layer_size[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_size[2], layer_size[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_size[3], layer_size[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_size[4], layer_size[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3,3,3,3,3,1]\n",
    "sample_input = torch.tensor([[1.,0.,-1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    print(f\"output:{output}\")\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    loss.backward()\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:tensor([[0.0622]], grad_fn=<MulBackward0>)\n",
      "layers.0.0.weight has gradient mean of 0.0002475684741511941\n",
      "layers.1.0.weight has gradient mean of 0.00015160041220951825\n",
      "layers.2.0.weight has gradient mean of 0.0008637128048576415\n",
      "layers.3.0.weight has gradient mean of 0.001529233530163765\n",
      "layers.4.0.weight has gradient mean of 0.005495645105838776\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the above example we see a vanishing gradientfrom layer 4 to layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now instantiate a model with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:tensor([[0.9603]], grad_fn=<MulBackward0>)\n",
      "layers.0.0.weight has gradient mean of 0.3107847571372986\n",
      "layers.1.0.weight has gradient mean of 0.2917015850543976\n",
      "layers.2.0.weight has gradient mean of 0.48102134466171265\n",
      "layers.3.0.weight has gradient mean of 0.39286816120147705\n",
      "layers.4.0.weight has gradient mean of 1.8537139892578125\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import MultiHeadAttention from chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout,\n",
    "                 num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "        \"d_out must be a divisible my num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_ptoj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        # The tensor shapes will be now (b, num_tokens, d_out)\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        \"\"\"\n",
    "        We implicitely split matrix by adding a num_heads dimension.\n",
    "        Then we unroll the last dim: \n",
    "        (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        \"\"\"\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        Transposes from shape (b, num_tokens, num_heads, head_dim) \n",
    "        to (b, num_heads, num_tokens, head_dim) \n",
    "        \"\"\"\n",
    "        keys = keys.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "        queries = queries.transpose(1,2)\n",
    "\n",
    "        #Compute dot product for each head\n",
    "        attn_scores = queries @ keys.transpose(2,3)\n",
    "        #masks truncated to number of token\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        # print(f\"mask_bool: {mask_bool}\")\n",
    "        #use the mask to fill the attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        #Tensor shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vecs = (attn_weights @ values).transpose(1,2)\n",
    "\n",
    "        #Combines heads, Where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vecs = context_vecs.contiguous().view(\n",
    "            b, num_tokens, self.d_out\n",
    "        )\n",
    "\n",
    "        #Adds an optional linear projection\n",
    "        context_vecs = self.out_ptoj(context_vecs)\n",
    "\n",
    "        return context_vecs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        # Add original input back\n",
    "        x = x + shortcut\n",
    "\n",
    "        #Shortcut for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x+shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed sample data to transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2,4,768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input Shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update the GPT model with transformerblock and layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb =nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_block = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_block(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "Output: \n",
      " tensor([[[ 0.3353,  0.4403, -0.0822,  ...,  0.3335,  0.4584, -0.3086],\n",
      "         [-0.2477, -0.5299, -1.0065,  ...,  0.0173,  0.5226, -0.3643],\n",
      "         [ 0.6933,  0.0323,  0.1004,  ...,  0.0297, -0.3547, -0.2467],\n",
      "         [-1.0391,  0.3932, -0.1123,  ...,  0.7301,  0.3848,  0.0335]],\n",
      "\n",
      "        [[-0.3025,  0.1131,  0.0043,  ...,  0.2131,  0.4553, -0.7163],\n",
      "         [ 0.0976,  0.3940, -0.2042,  ...,  0.7415,  0.2714,  0.1652],\n",
      "         [ 1.0650,  1.0320, -0.2525,  ...,  0.6274,  0.3092, -0.3420],\n",
      "         [-0.2596,  0.4945,  0.3291,  ...,  1.2046, -0.2345,  0.0429]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "Output Shape: torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(f\"Input batch:\\n {batch}\")\n",
    "print(f\"Output: \\n {out}\")\n",
    "print(f\"Output Shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:163009536\n"
     ]
    }
   ],
   "source": [
    "total_params =sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters:{total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we were supposed to 124 million parameter but now we have 163 million"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because of the concept called as weight tying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the GPT-2 reuses the weights from the token embedding layer in its output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token Embedding layer shape: {model.tok_emb.weight.shape}\")\n",
    "print(f\"Output layer shape: {model.out_head.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we remove the output layer parameters count from the total GPT-2 model count according to weight tying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters, cosidering weight tying: 124412160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "    total_params - sum(p.numel()\n",
    "    for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Number of trainable parameters, cosidering weight tying: {total_params_gpt2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "displaying total transformers parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85026816"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_trf_params = sum(p.numel() for p in model.trf_block.parameters())\n",
    "total_trf_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "displaying total feedforward parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56669184"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ff_parameters = sum(p.numel() for block in model.trf_block for p in block.ff.parameters())\n",
    "total_ff_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "displaying total attention parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28320768"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_attn_parameters = sum(p.numel() for block in model.trf_block for p in block.att.parameters())\n",
    "total_attn_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory requirements for 163 million parameters (assuming 1 float32 parameter requires 4 bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83203125 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate text from last vector from the GPT output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx is a (batch_size, n_tokens) array of indices in the current context\n",
    "def generate_text_sample(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        \"\"\"\n",
    "        crops current context if it exceeds the supported context size\n",
    "        eg: if LLM supports only 5 tokens and the context size is 10\n",
    "        only 5 tokens are used as context\n",
    "        \"\"\"\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        \"\"\"\n",
    "        Focuses only on the last time step so that (batch_size, n_tokens, vocab_size)\n",
    "        becomes (batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "        logits = logits[:,-1,:]\n",
    "        # probas has shape (batch_size, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        # idx_next has shape (batch_size, 1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        \"\"\"\n",
    "        Append sampled index tot he running sequence\n",
    "        where idx has shape (batch, n_tokens+1)\n",
    "        \"\"\"\n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate text sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor: tensor([[15496,    11,   314,   716]])\n",
      "encoded tensor shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(f\"encoded: {encoded}\")\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(f\"encoded_tensor: {encoded_tensor}\")\n",
    "print(f\"encoded tensor shape: {encoded_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 29739,   554]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_sample(\n",
    "    model = model,\n",
    "    idx = encoded_tensor,\n",
    "    max_new_tokens = 6,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Output: {out}\")\n",
    "print(f\"Output length: {len(out[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decode token id into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswick Exit In\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
